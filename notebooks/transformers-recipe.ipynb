{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (4.4.2)\n",
      "Requirement already satisfied: torch in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (1.8.0+cu111)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (1.5.0)\n",
      "Requirement already satisfied: rouge_score in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.0.4)\n",
      "Requirement already satisfied: jiwer in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: mlflow in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (1.19.2)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: dill in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (4.49.0)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (1.2.2)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (0.0.7)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: python-Levenshtein in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from jiwer) (0.12.2)\n",
      "Requirement already satisfied: docker>=4.0.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (4.4.4)\n",
      "Requirement already satisfied: sqlalchemy in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (1.3.23)\n",
      "Requirement already satisfied: entrypoints in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (0.4.1)\n",
      "Requirement already satisfied: cloudpickle in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (1.6.0)\n",
      "Requirement already satisfied: gunicorn in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (5.4.1)\n",
      "Requirement already satisfied: alembic<=1.4.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (1.4.1)\n",
      "Requirement already satisfied: pytz in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (2021.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (3.15.6)\n",
      "Requirement already satisfied: Flask in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (1.1.2)\n",
      "Requirement already satisfied: querystring-parser in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (0.14.3)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (3.1.14)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from mlflow) (0.18.1)\n",
      "Requirement already satisfied: Mako in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (1.1.4)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
      "Requirement already satisfied: python-editor>=0.3 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from docker>=4.0.0->mlflow) (0.58.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from rouge_score) (3.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (0.0.44)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from Flask->mlflow) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from Flask->mlflow) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from gunicorn->mlflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from nltk->rouge_score) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: prometheus-client in /home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch datasets rouge_score jiwer mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "optimum-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, load_metric, list_datasets, list_metrics\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, BasicTokenizer\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "reliable-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace, Split\n",
    "\n",
    "output_vocab = {\n",
    "    \"[PAD]\": 0,\n",
    "    \"[BOS]\": 1,\n",
    "    \"PUT\":2,\n",
    "    \"REMOVE\":3,\n",
    "    \"USE\":4,\n",
    "    \"STOP_USING\":5,\n",
    "    \"CHEF_CHECK\":6,\n",
    "    \"CHEF_DO\":7,\n",
    "    \"MOVE_CONTENTS\":8,\n",
    "}\n",
    "k = len(output_vocab)\n",
    "with open(\"res2idx.json\", 'r') as f:\n",
    "    for w,i in json.load(f).items():\n",
    "        output_vocab[w] = k\n",
    "        k+=1\n",
    "with open(\"arg2idx.json\", 'r') as f:\n",
    "    for w,i in json.load(f).items():\n",
    "#         output_vocab[w] = k\n",
    "        output_vocab[w.replace('-','_')] = k\n",
    "        k+=1\n",
    "\n",
    "output_vocab = {w:i for i,w in enumerate(output_vocab)}\n",
    "output_tokenizer = Tokenizer(WordLevel(output_vocab,))\n",
    "output_tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "unlikely-birmingham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=2, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=3, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.encode_batch([\"SERVE MOVE_CONTENTS\",\"SERVE MOVE_CONTENTS PUT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "loving-heating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 8], [9, 8, 2]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.ids for t in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "swiss-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://3.249.199.3:5000\")\n",
    "mlflow.set_experiment(\"my-experiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "compressed-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased') # initialize Bert2Bert from pre-trained checkpoints\n",
    "# # forward\n",
    "# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "# outputs = model(input_ids=input_ids, decoder_input_ids=input_ids)\n",
    "# # training\n",
    "# outputs = model(input_ids=input_ids, decoder_input_ids=input_ids, labels=input_ids)\n",
    "# loss, logits = outputs.loss, outputs.logits\n",
    "# # save and load from pretrained\n",
    "# model.save_pretrained(\"bert2bert\")\n",
    "# model = EncoderDecoderModel.from_pretrained(\"bert2bert\")\n",
    "# # generation\n",
    "# generated = model.generate(input_ids, decoder_start_token_id=model.config.decoder.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "departmental-surge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b6e1a9e6d71b3baf\n",
      "Reusing dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-b6e1a9e6d71b3baf/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
      "Using custom data configuration default-b6e1a9e6d71b3baf\n",
      "Reusing dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-b6e1a9e6d71b3baf/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_seq', 'output_seq'],\n",
      "    num_rows: 50\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_seq', 'output_seq'],\n",
      "    num_rows: 451\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'seq2seq_4335716.csv'\n",
    "input_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "input_tokenizer.bos_token = input_tokenizer.cls_token\n",
    "input_tokenizer.eos_token = input_tokenizer.sep_token\n",
    "\n",
    "val_data = load_dataset('csv', data_files=csv_file, split='train[90%:]')\n",
    "train_data = load_dataset('csv', data_files=csv_file, split='train[:90%]')\n",
    "print(val_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "healthy-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STOP_USING TSPATULA STOVE_MED CHEF_CHECK LBOIL STOVE_MED',\n",
       " 'USE TSPATULA STOVE_MED PUT IN2e0UIJI STOVE_MED',\n",
       " 'MOVE_CONTENTS STOVE_MED STOVE_MEDLOW USE TPAN STOVE_MEDLOW STOP_USING TPAN STOVE_MED STOP_USING TSPATULA STOVE_MED CHEF_CHECK LTIME STOVE_MEDLOW',\n",
       " 'USE TSPATULA STOVE_MEDLOW PUT IzrIHcuDJ STOVE_MEDLOW PUT IrXTUISnn STOVE_MEDLOW',\n",
       " 'MOVE_CONTENTS STOVE_MED SERVE MOVE_CONTENTS STOVE_MEDLOW SERVE STOP_USING TPAN STOVE_MEDLOW STOP_USING TSPATULA STOVE_MEDLOW PUT Is_lS1dmt SERVE',\n",
       " 'USE TBOWL COUNTER1 PUT IzrIHcuDJ COUNTER1 PUT IzPYYTv5e COUNTER1 PUT IdCkp3LYx COUNTER1 PUT Is_lS1dmt COUNTER1',\n",
       " 'MOVE_CONTENTS COUNTER1 OVEN_MED USE TBAKE_DISH OVEN_MED STOP_USING TBOWL COUNTER1 CHEF_CHECK LTIME OVEN_MED',\n",
       " 'MOVE_CONTENTS OVEN_MED COUNTER1 USE TPAN COUNTER1 STOP_USING TBAKE_DISH OVEN_MED PUT IoskwJgPz COUNTER1 PUT IlGA3C7DK COUNTER1 PUT IraFb0aXd COUNTER1 PUT I6WhEfvid COUNTER1',\n",
       " 'MOVE_CONTENTS COUNTER1 STOVE_MED MOVE_CONTENTS OVEN_MED STOVE_MED USE TPAN STOVE_MED STOP_USING TPAN COUNTER1 CHEF_CHECK LMELT STOVE_MED',\n",
       " 'MOVE_CONTENTS COUNTER1 OVEN_HI MOVE_CONTENTS STOVE_MED OVEN_HI MOVE_CONTENTS OVEN_MED OVEN_HI USE TPAN OVEN_HI STOP_USING TPAN STOVE_MED CHEF_CHECK LTIME OVEN_HI',\n",
       " 'MOVE_CONTENTS COUNTER1 SERVE MOVE_CONTENTS OVEN_HI SERVE MOVE_CONTENTS STOVE_MED SERVE MOVE_CONTENTS OVEN_MED SERVE USE TPAN SERVE STOP_USING TPAN OVEN_HI',\n",
       " 'USE TSKILLET STOVE_LOW USE TSPATULA STOVE_LOW PUT IzPYYTv5e STOVE_LOW PUT Iz0wiMjVJ STOVE_LOW PUT I10_d4pRP STOVE_LOW CHEF_CHECK LBROWN STOVE_LOW',\n",
       " 'MOVE_CONTENTS STOVE_LOW COUNTER1 USE TPLATE COUNTER1 STOP_USING TSPATULA STOVE_LOW STOP_USING TSKILLET STOVE_LOW PUT IlGA3C7DK COUNTER1 PUT IzrIHcuDJ COUNTER1 PUT I5IP2D1SP COUNTER1 PUT IBhyfTisH COUNTER1',\n",
       " 'MOVE_CONTENTS COUNTER1 STOVE_MEDLOW MOVE_CONTENTS STOVE_LOW STOVE_MEDLOW USE TSKILLET STOVE_MEDLOW STOP_USING TPLATE COUNTER1 CHEF_CHECK LBOIL STOVE_MEDLOW CHEF_CHECK LTIME STOVE_MEDLOW',\n",
       " 'MOVE_CONTENTS COUNTER1 SERVE MOVE_CONTENTS STOVE_LOW SERVE MOVE_CONTENTS STOVE_MEDLOW SERVE USE TBOWL SERVE STOP_USING TSKILLET STOVE_MEDLOW',\n",
       " 'PUT I23cXSqNN COUNTER1 PUT Is_lS1dmt COUNTER1 PUT Iz0wiMjVJ COUNTER1',\n",
       " 'USE TBOWL COUNTER1',\n",
       " 'PUT ITgJlN6fT COUNTER1 PUT Ine5Fok7_ COUNTER1 CHEF_CHECK LTIME COUNTER1',\n",
       " 'USE TPAN COUNTER1 STOP_USING TBOWL COUNTER1 CHEF_CHECK LSIDES COUNTER1',\n",
       " 'CHEF_CHECK LTEXTURE COUNTER1',\n",
       " 'MOVE_CONTENTS COUNTER1 SERVE USE TPLATE SERVE STOP_USING TPAN COUNTER1',\n",
       " 'USE TPAN STOVE_HI PUT IlGA3C7DK STOVE_HI CHEF_CHECK LBOIL STOVE_HI',\n",
       " 'MOVE_CONTENTS STOVE_HI STOVE_MED USE TPAN STOVE_MED STOP_USING TPAN STOVE_HI PUT Iz0wiMjVJ STOVE_MED',\n",
       " 'CHEF_CHECK LTEXTURE STOVE_MED CHEF_CHECK LINSIDE STOVE_MED',\n",
       " 'MOVE_CONTENTS STOVE_MED STOVE_LOW MOVE_CONTENTS STOVE_HI STOVE_LOW USE TPAN STOVE_LOW STOP_USING TPAN STOVE_MED',\n",
       " 'PUT IzPYYTv5e STOVE_LOW PUT IRghrxgvV STOVE_LOW PUT IraFb0aXd STOVE_LOW PUT IBhyfTisH STOVE_LOW PUT IQxauuYZx STOVE_LOW',\n",
       " 'CHEF_CHECK LTEXTURE STOVE_LOW CHEF_CHECK LTIME STOVE_LOW',\n",
       " 'USE TSKILLET STOVE_MEDLOW PUT I10_d4pRP STOVE_MEDLOW',\n",
       " 'PUT I1IusNkrV STOVE_MEDLOW PUT Iz0wiMjVJ STOVE_MEDLOW CHEF_CHECK LSIDES STOVE_MEDLOW',\n",
       " 'PUT IraFb0aXd STOVE_MEDLOW PUT IfztrkJfj STOVE_MEDLOW PUT Is_lS1dmt STOVE_MEDLOW PUT IzrIHcuDJ STOVE_MEDLOW PUT IzDRSSnRu STOVE_MEDLOW PUT I6WhEfvid STOVE_MEDLOW PUT IaeZBN7Aq STOVE_MEDLOW CHEF_CHECK LTIME STOVE_MEDLOW',\n",
       " 'MOVE_CONTENTS STOVE_MEDLOW SERVE USE TSKILLET SERVE STOP_USING TSKILLET STOVE_MEDLOW',\n",
       " 'USE TSKILLET STOVE_MED PUT IJAkkJI6_ STOVE_MED',\n",
       " 'PUT IpGQkiesK STOVE_MED PUT IT_JYeEg2 STOVE_MED PUT Iz0wiMjVJ STOVE_MED',\n",
       " 'USE TSPATULA STOVE_MED CHEF_CHECK LTEXTURE STOVE_MED',\n",
       " 'PUT IrXTUISnn STOVE_MED PUT Is_lS1dmt STOVE_MED PUT I_qDx9v7e STOVE_MED PUT IxUjqmQ6R STOVE_MED CHEF_CHECK LTEXTURE STOVE_MED',\n",
       " 'MOVE_CONTENTS STOVE_MED STOVE_LOW USE TSKILLET STOVE_LOW STOP_USING TSKILLET STOVE_MED STOP_USING TSPATULA STOVE_MED',\n",
       " 'CHEF_CHECK LTIME STOVE_LOW CHEF_CHECK LSOLID STOVE_LOW',\n",
       " 'USE TGRATER COUNTER1 PUT IjuICeYOR COUNTER1',\n",
       " 'USE TGRATER COUNTER2 PUT IT_JYeEg2 COUNTER2',\n",
       " 'USE TSKILLET STOVE_MEDHI PUT Ixa8FQ0B6 STOVE_MEDHI',\n",
       " 'REMOVE IjuICeYOR COUNTER1 REMOVE IT_JYeEg2 COUNTER2 REMOVE Ixa8FQ0B6 STOVE_MEDHI STOP_USING TGRATER COUNTER2 STOP_USING TSKILLET STOVE_MEDHI PUT IT_JYeEg2 COUNTER1',\n",
       " 'REMOVE IT_JYeEg2 COUNTER1 USE TSKILLET STOVE_MEDHI STOP_USING TGRATER COUNTER1 PUT Ixa8FQ0B6 STOVE_MEDHI PUT IjuICeYOR STOVE_MEDHI CHEF_CHECK LTIME STOVE_MEDHI',\n",
       " 'REMOVE Ixa8FQ0B6 STOVE_MEDHI REMOVE IjuICeYOR STOVE_MEDHI USE TGRATER COUNTER1 STOP_USING TSKILLET STOVE_MEDHI PUT IT_JYeEg2 COUNTER1',\n",
       " 'USE TPAN STOVE_MED USE TCOOK_SPRAY STOVE_MED PUT Iz0wiMjVJ STOVE_MED',\n",
       " 'PUT I1IusNkrV STOVE_MED PUT IzPYYTv5e STOVE_MED PUT IAF0F3ilI STOVE_MED CHEF_CHECK LTIME STOVE_MED',\n",
       " 'PUT IsxiK2rPw STOVE_MED CHEF_CHECK LTIME STOVE_MED',\n",
       " 'USE TFOIL STOVE_MED PUT IzrIHcuDJ STOVE_MED PUT Is_lS1dmt STOVE_MED CHEF_CHECK LTIME STOVE_MED',\n",
       " 'PUT IN2e0UIJI STOVE_MED CHEF_CHECK LTIME STOVE_MED',\n",
       " 'PUT I_qDx9v7e STOVE_MED CHEF_CHECK LTIME STOVE_MED',\n",
       " 'MOVE_CONTENTS STOVE_MED SERVE USE TCOOK_SPRAY SERVE USE TPAN SERVE USE TFOIL SERVE STOP_USING TCOOK_SPRAY STOVE_MED STOP_USING TPAN STOVE_MED STOP_USING TFOIL STOVE_MED']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['output_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "processed-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # 4 but change to 16 for full training\n",
    "encoder_max_length = 128\n",
    "decoder_max_length = 128\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    tok_params = {\n",
    "        'padding': 'max_length',\n",
    "        'truncation': True,\n",
    "        'max_length': encoder_max_length,\n",
    "    }\n",
    "    inputs = input_tokenizer(batch['input_seq'], **tok_params)\n",
    "    #outputs = output_tokenizer(batch['output_seq'], **tok_params)\n",
    "    outputs = output_tokenizer.encode_batch(batch['output_seq'])\n",
    "    # pad\n",
    "    padded_output = np.zeros((len(outputs),decoder_max_length-1))\n",
    "    attention_output = np.zeros((len(outputs),decoder_max_length))\n",
    "    for i,arr in enumerate(outputs):\n",
    "        padded_output[i,:len(arr.ids)] = arr.ids\n",
    "        attention_output[i,:len(arr.ids)] = 1\n",
    "    padded_output=np.concatenate([np.ones((len(outputs),1)),padded_output],axis=1).astype(int)\n",
    "    attention_output=attention_output.astype(int)\n",
    "    \n",
    "    batch['input_ids'] = inputs.input_ids\n",
    "    batch['attention_mask'] = inputs.attention_mask\n",
    "    batch['decoder_input_ids'] = padded_output\n",
    "    batch['decoder_attention_mask'] =attention_output\n",
    "    batch['labels'] = padded_output\n",
    "\n",
    "    # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`.\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "#     batch['labels'] = [\n",
    "#         [-100 if token == output_tokenizer.pad_token_id else token for token in labels] for labels in batch['labels']\n",
    "#     ]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "working-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-b6e1a9e6d71b3baf/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-dbb95374d2b40c61.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-b6e1a9e6d71b3baf/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-ebeb16ec743a2cf7.arrow\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Trainer is attempting to log a value of \"{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'use_bfloat16': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'architectures': ['BertForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': 0, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, '_name_or_path': 'bert-base-uncased', 'vocab_size': 30522, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 512, 'type_vocab_size': 2, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12, 'gradient_checkpointing': False, 'position_embedding_type': 'absolute', 'use_cache': True, 'model_type': 'bert', 'transformers_version': '4.4.2'}\" for key \"encoder\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'use_bfloat16': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': True, 'add_cross_attention': True, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'architectures': ['BertForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': 0, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, '_name_or_path': 'bert-base-uncased', 'vocab_size': 30522, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 512, 'type_vocab_size': 2, 'initializer_range': 0.02, 'layer_norm_eps': 1e-12, 'gradient_checkpointing': False, 'position_embedding_type': 'absolute', 'use_cache': True, 'model_type': 'bert', 'transformers_version': '4.4.2'}\" for key \"decoder\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 16:55, Epoch 34/35]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.820600</td>\n",
       "      <td>0.803495</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>31.336300</td>\n",
       "      <td>1.596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.638400</td>\n",
       "      <td>0.646926</td>\n",
       "      <td>0.380100</td>\n",
       "      <td>31.557200</td>\n",
       "      <td>1.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.605358</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>32.151800</td>\n",
       "      <td>1.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.621900</td>\n",
       "      <td>0.600292</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>31.006900</td>\n",
       "      <td>1.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.628100</td>\n",
       "      <td>0.593134</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>31.512500</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.453921</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>30.888500</td>\n",
       "      <td>1.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.353050</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>30.820500</td>\n",
       "      <td>1.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.336500</td>\n",
       "      <td>0.350486</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>30.034600</td>\n",
       "      <td>1.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.323977</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>30.120900</td>\n",
       "      <td>1.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.307198</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>29.495900</td>\n",
       "      <td>1.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.281325</td>\n",
       "      <td>0.951800</td>\n",
       "      <td>30.052700</td>\n",
       "      <td>1.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.273523</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>31.140900</td>\n",
       "      <td>1.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.270098</td>\n",
       "      <td>0.933800</td>\n",
       "      <td>30.966100</td>\n",
       "      <td>1.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.258397</td>\n",
       "      <td>0.921400</td>\n",
       "      <td>31.864300</td>\n",
       "      <td>1.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.263513</td>\n",
       "      <td>0.928500</td>\n",
       "      <td>31.661300</td>\n",
       "      <td>1.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.262108</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>30.772400</td>\n",
       "      <td>1.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.264663</td>\n",
       "      <td>0.906300</td>\n",
       "      <td>31.541900</td>\n",
       "      <td>1.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.270585</td>\n",
       "      <td>0.908200</td>\n",
       "      <td>30.316800</td>\n",
       "      <td>1.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.273736</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>30.430400</td>\n",
       "      <td>1.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.275105</td>\n",
       "      <td>0.904600</td>\n",
       "      <td>31.785600</td>\n",
       "      <td>1.573000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.593121000289917, metrics={'train_runtime': 1015.5104, 'train_samples_per_second': 0.985, 'total_flos': 5911264603219968.0, 'epoch': 34.48, 'init_mem_cpu_alloc_delta': 50960, 'init_mem_gpu_alloc_delta': 996802048, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 353741, 'train_mem_gpu_alloc_delta': 3107204096, 'train_mem_cpu_peaked_delta': 96154506, 'train_mem_gpu_peaked_delta': 4824370688})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use 32 training examples for notebook - COMMENT LINE FOR FULL TRAINING\n",
    "#train_data = train_data.select(range(32))\n",
    "\n",
    "train_data = train_data.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "#     remove_columns=['name', 'note'],\n",
    ")\n",
    "train_data.set_format(\n",
    "    type='torch',\n",
    "    columns=['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'labels'],\n",
    ")\n",
    "\n",
    "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
    "# val_data = val_data.select(range(16))\n",
    "\n",
    "val_data = val_data.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "#     remove_columns=['name', 'note'],\n",
    ")\n",
    "val_data.set_format(\n",
    "    type='torch',\n",
    "    columns=['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'labels'],\n",
    ")\n",
    "\n",
    "ed_model = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased')\n",
    "\n",
    "# set special tokens\n",
    "ed_model.config.decoder_start_token_id = 1\n",
    "ed_model.config.eos_token_id = input_tokenizer.eos_token_id\n",
    "ed_model.config.pad_token_id = input_tokenizer.pad_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "ed_model.config.vocab_size = len(output_vocab)\n",
    "ed_model.config.max_length = 142\n",
    "ed_model.config.min_length = 56\n",
    "ed_model.config.no_repeat_ngram_size = 3\n",
    "ed_model.config.early_stopping = True\n",
    "ed_model.config.length_penalty = 2.0\n",
    "ed_model.config.num_beams = 4\n",
    "\n",
    "\n",
    "# load wer for validation\n",
    "wer = load_metric('wer')\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = output_tokenizer.decode_batch(pred_ids)\n",
    "    #labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = output_tokenizer.decode_batch(labels_ids)\n",
    "    #label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer_output = wer.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\n",
    "        'wer': round(wer_output, 4),\n",
    "    }\n",
    "\n",
    "\n",
    "# set training arguments - these params are not really tuned, feel free to change\n",
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     output_dir='./',\n",
    "#     evaluation_strategy='steps',\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     predict_with_generate=True,\n",
    "#     logging_steps=500,  # 2 or set to 1000 for full training\n",
    "#     save_steps=500,  # 16 or set to 500 for full training\n",
    "#     eval_steps=500,  # 4 or set to 8000 for full training\n",
    "#     warmup_steps=500,  # 1 or set to 2000 for full training\n",
    "#     max_steps=2500,  # 16 or comment for full training\n",
    "#     overwrite_output_dir=True,\n",
    "#     save_total_limit=3,\n",
    "#     fp16=torch.cuda.is_available(),\n",
    "# )\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./',\n",
    "    evaluation_strategy='steps',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=50,  # 2 or set to 1000 for full training\n",
    "    save_steps=50,  # 16 or set to 500 for full training\n",
    "    eval_steps=50,  # 4 or set to 8000 for full training\n",
    "    warmup_steps=50,  # 1 or set to 2000 for full training\n",
    "    max_steps=850,  # 16 or comment for full training\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=ed_model,\n",
    "    tokenizer=input_tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-education",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "alternate-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "upload: recipe_bert_seq2seq/config.json to s3://uatt-data/uri/config.json\n",
      "upload: recipe_bert_seq2seq/pytorch_model.bin to s3://uatt-data/uri/pytorch_model.bin\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n"
     ]
    }
   ],
   "source": [
    "ed_model.save_pretrained(\"recipe_bert_seq2seq\")\n",
    "!aws s3 cp --recursive recipe_bert_seq2seq s3://uatt-data/uri/\n",
    "!rm -rf recipe_bert_seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-robin",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "constitutional-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"Cook chicken until golden brown .\"\n",
    "input_ids = torch.tensor(input_tokenizer.encode(input_text, add_special_tokens=True)).unsqueeze(0).to(device)  # Batch size 1\n",
    "generated = ed_model.generate(input_ids, decoder_start_token_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "controversial-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[BOS] MOVE_CONTENTS MOVE_CONTENTS STOVE_MED USE TPAN STOVE_MED STOP_USING TPAN STOVE_MED PUT LTIME STOVE_MED CHEF_CHECK LTIME STOVE_MEDLOW CHEF_CHECK LTIME STOVE_MEDHI CHEF_CHECK LTIME STOVE_MED [PAD] CHEF_CHECK STOVE_MED CHEF_CHECK LBOIL STOVE_MED CHEF_CHECK LBROWN STOVE_MED CHEF_CHECK LTEXTURE STOVE_MED CHEF_CHECK CHEF_CHECK LTIME CHEF_CHECK LBROWN LTIME CHEF_CHECK LTIME LTIME STOVE_MED PUT LBOIL LTIME LTIME LTIME STOVE_MEDLOW [PAD] CHEF_CHECK LTIME LBROWN LTIME LTIME LBOIL LTIME LBROWN [PAD] CHEF_CHECK CHEF_CHECK LBROWN LBROWN CHEF_CHECK LTIME LBOIL [PAD] LTIME LTIME CHEF_CHECK LBOIL LTIME LBOIL STOVE_MED [PAD] LTIME LBOIL CHEF_CHECK LTIME InaG8xAmv STOVE_MED [PAD] STOVE_MED [PAD] PUT CHEF_CHECK LTIME LTEXTURE CHEF_CHECK LTIME Iz0wiMjVJ [PAD] CHEF_CHECK STOP_USING LTIME LTIME LTEXTURE LTIME LTIME STOVE_MEDHI [PAD] CHEF_CHECK [PAD] CHEF_CHECK PUT LTIME LTIME InaG8xAmv CHEF_CHECK LTIME LMELT LTIME LTIME LMELT STOVE_MED LTIME LTIME Iz0wiMjVJ LTIME LTIME IAG_HiS9H LTIME LTIME IRghrxgvV CHEF_CHECK LTIME IAG_HiS9H CHEF_CHECK LTIME IRghrxgvV LTIME LTIME IeBMljvjG LTIME LTIME LBROWN STOVE_MEDLOW LTIME LTIME LSHAPE LTIME'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = generated.to('cpu').numpy().reshape(-1)\n",
    "output_tokenizer.decode(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "coral-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "upload: ./transformers-recipe.ipynb to s3://uatt-notebooks/transformers-recipe.ipynb\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp transformers-recipe.ipynb s3://uatt-notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-patch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
