{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "resistant-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, collections, itertools,random\n",
    "from copy import deepcopy as clone\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, classification_report\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "numeric-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-northeast",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjustable-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = {\n",
    "    0:\"nothing\",\n",
    "    1:\"put\",\n",
    "    2:\"remove\",\n",
    "    3:\"use\",\n",
    "    4:\"unuse\",\n",
    "    5:\"check\",\n",
    "    6:\"do\",\n",
    "    7:\"move\",\n",
    "}\n",
    "command2idx = {\n",
    "        \"NOOP\": 0,\n",
    "        \"PUT\": 1,\n",
    "        \"REMOVE\": 2,\n",
    "        \"USE\": 3,\n",
    "        \"STOP_USING\": 4,\n",
    "        \"CHEF_CHECK\": 5,\n",
    "        \"CHEF_DO\": 6,\n",
    "        \"MOVE_CONTENTS\": 7,\n",
    "    }\n",
    "with open(\"../data/ingredients.json\", 'r') as f:\n",
    "    ingredients = dict(json.load(f))\n",
    "with open(\"../data/resources.json\", 'r') as f:\n",
    "    resources = json.load(f)\n",
    "    resources = [(r[\"id\"], r[\"name\"]) for r in resources if 'children' not in r] + [(r[\"id\"], lst[\"name\"]+'/'+r[\"name\"]) for lst in resources if 'children' in lst for r in lst[\"children\"]]\n",
    "    resources = {k:v for k,v in resources if not k.startswith(\"VALID_\")}\n",
    "    res2idx = {k:i for i,k in enumerate(resources.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disturbed-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg2idx = res2idx\n",
    "k=len(arg2idx)+1\n",
    "with open(\"../data/arg2idx.json\", 'r') as f:\n",
    "    for w, i in json.load(f).items():\n",
    "        arg2idx[w.replace('-', '_')] = k\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "separate-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2arg = {i:ingredients.get(v,v) for v,i in arg2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-supervisor",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saved-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_seq</th>\n",
       "      <th>output_seq</th>\n",
       "      <th>triplet_n</th>\n",
       "      <th>triplet_lst</th>\n",
       "      <th>triplet_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>melt butter .</td>\n",
       "      <td>USE TBOWL OVEN_MED PUT I10_d4pRP OVEN_MED CHEF...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[USE, TBOWL, OVEN_MED], [PUT, I10_d4pRP, OVEN...</td>\n",
       "      <td>[USE, TBOWL, OVEN_MED]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>salt and freshly ground black pepper to taste ...</td>\n",
       "      <td>USE TSKILLET COUNTER1 PUT IzPYYTv5e COUNTER1 P...</td>\n",
       "      <td>8</td>\n",
       "      <td>[[USE, TSKILLET, COUNTER1], [PUT, IzPYYTv5e, C...</td>\n",
       "      <td>[USE, TSKILLET, COUNTER1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>then pour back into bottle and store in fridge .</td>\n",
       "      <td>USE TPOT COUNTER1 STOP_USING TBOWL COUNTER1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[USE, TPOT, COUNTER1], [STOP_USING, TBOWL, CO...</td>\n",
       "      <td>[USE, TPOT, COUNTER1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>oven about 40 minutes or till chicken is no lo...</td>\n",
       "      <td>MOVE_CONTENTS COUNTER1 SERVE MOVE_CONTENTS STO...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER1, SERVE], [MOVE_CONTE...</td>\n",
       "      <td>[MOVE_CONTENTS, COUNTER1, SERVE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>in a buttered 11/2 quart casserole , layer the...</td>\n",
       "      <td>MOVE_CONTENTS COUNTER2 COUNTER1 USE TBAKE_DISH...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER2, COUNTER1], [USE, TB...</td>\n",
       "      <td>[MOVE_CONTENTS, COUNTER2, COUNTER1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>add onion and cook until tender .</td>\n",
       "      <td>MOVE_CONTENTS APPL_BLEND STOVE_MEDLOW MOVE_CON...</td>\n",
       "      <td>6</td>\n",
       "      <td>[[MOVE_CONTENTS, APPL_BLEND, STOVE_MEDLOW], [M...</td>\n",
       "      <td>[MOVE_CONTENTS, APPL_BLEND, STOVE_MEDLOW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>MOVE_CONTENTS STOVE_MED FAUCET_OFF USE TSKILLE...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[MOVE_CONTENTS, STOVE_MED, FAUCET_OFF], [USE,...</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>mix tomatoes , salt , pepper , sugar and dry m...</td>\n",
       "      <td>USE TBOWL COUNTER1 PUT IzrIHcuDJ COUNTER1 PUT ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[[USE, TBOWL, COUNTER1], [PUT, IzrIHcuDJ, COUN...</td>\n",
       "      <td>[USE, TBOWL, COUNTER1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>serve this delicious starter with a very chill...</td>\n",
       "      <td>MOVE_CONTENTS COUNTER1 SERVE MOVE_CONTENTS REF...</td>\n",
       "      <td>6</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER1, SERVE], [MOVE_CONTE...</td>\n",
       "      <td>[MOVE_CONTENTS, COUNTER1, SERVE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>heat through and serve .</td>\n",
       "      <td>MOVE_CONTENTS STOVE_MEDHI COUNTER1 MOVE_CONTEN...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[MOVE_CONTENTS, STOVE_MEDHI, COUNTER1], [MOVE...</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MEDHI, COUNTER1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_seq  \\\n",
       "81                                       melt butter .   \n",
       "236  salt and freshly ground black pepper to taste ...   \n",
       "252   then pour back into bottle and store in fridge .   \n",
       "127  oven about 40 minutes or till chicken is no lo...   \n",
       "217  in a buttered 11/2 quart casserole , layer the...   \n",
       "83                   add onion and cook until tender .   \n",
       "1        remove from heat and drain the fat , if any .   \n",
       "214  mix tomatoes , salt , pepper , sugar and dry m...   \n",
       "332  serve this delicious starter with a very chill...   \n",
       "193                           heat through and serve .   \n",
       "\n",
       "                                            output_seq  triplet_n  \\\n",
       "81   USE TBOWL OVEN_MED PUT I10_d4pRP OVEN_MED CHEF...          3   \n",
       "236  USE TSKILLET COUNTER1 PUT IzPYYTv5e COUNTER1 P...          8   \n",
       "252        USE TPOT COUNTER1 STOP_USING TBOWL COUNTER1          2   \n",
       "127  MOVE_CONTENTS COUNTER1 SERVE MOVE_CONTENTS STO...          5   \n",
       "217  MOVE_CONTENTS COUNTER2 COUNTER1 USE TBAKE_DISH...          5   \n",
       "83   MOVE_CONTENTS APPL_BLEND STOVE_MEDLOW MOVE_CON...          6   \n",
       "1    MOVE_CONTENTS STOVE_MED FAUCET_OFF USE TSKILLE...          3   \n",
       "214  USE TBOWL COUNTER1 PUT IzrIHcuDJ COUNTER1 PUT ...          6   \n",
       "332  MOVE_CONTENTS COUNTER1 SERVE MOVE_CONTENTS REF...          6   \n",
       "193  MOVE_CONTENTS STOVE_MEDHI COUNTER1 MOVE_CONTEN...          5   \n",
       "\n",
       "                                           triplet_lst  \\\n",
       "81   [[USE, TBOWL, OVEN_MED], [PUT, I10_d4pRP, OVEN...   \n",
       "236  [[USE, TSKILLET, COUNTER1], [PUT, IzPYYTv5e, C...   \n",
       "252  [[USE, TPOT, COUNTER1], [STOP_USING, TBOWL, CO...   \n",
       "127  [[MOVE_CONTENTS, COUNTER1, SERVE], [MOVE_CONTE...   \n",
       "217  [[MOVE_CONTENTS, COUNTER2, COUNTER1], [USE, TB...   \n",
       "83   [[MOVE_CONTENTS, APPL_BLEND, STOVE_MEDLOW], [M...   \n",
       "1    [[MOVE_CONTENTS, STOVE_MED, FAUCET_OFF], [USE,...   \n",
       "214  [[USE, TBOWL, COUNTER1], [PUT, IzrIHcuDJ, COUN...   \n",
       "332  [[MOVE_CONTENTS, COUNTER1, SERVE], [MOVE_CONTE...   \n",
       "193  [[MOVE_CONTENTS, STOVE_MEDHI, COUNTER1], [MOVE...   \n",
       "\n",
       "                                 triplet_first  \n",
       "81                      [USE, TBOWL, OVEN_MED]  \n",
       "236                  [USE, TSKILLET, COUNTER1]  \n",
       "252                      [USE, TPOT, COUNTER1]  \n",
       "127           [MOVE_CONTENTS, COUNTER1, SERVE]  \n",
       "217        [MOVE_CONTENTS, COUNTER2, COUNTER1]  \n",
       "83   [MOVE_CONTENTS, APPL_BLEND, STOVE_MEDLOW]  \n",
       "1       [MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]  \n",
       "214                     [USE, TBOWL, COUNTER1]  \n",
       "332           [MOVE_CONTENTS, COUNTER1, SERVE]  \n",
       "193     [MOVE_CONTENTS, STOVE_MEDHI, COUNTER1]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def triplet_split(s):\n",
    "    ret = []\n",
    "    s=s.split()\n",
    "    for i,t in enumerate(s):\n",
    "        if i%3==0:\n",
    "            ret.append([])\n",
    "        ret[-1].append(t)\n",
    "    return ret\n",
    "df = pd.read_csv(\"seq2seq_4335716.csv\")\n",
    "df[\"triplet_n\"] = df[\"output_seq\"].str.split().str.len()//3\n",
    "df[\"triplet_lst\"] = df[\"output_seq\"].apply(triplet_split)\n",
    "df[\"triplet_first\"] = df[\"triplet_lst\"].apply(lambda x:x[0])\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "overhead-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"triplet_n\"].plot.hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "under-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_idx = list(df.index)\n",
    "random.shuffle(sentence_idx)\n",
    "train_idx = sentence_idx[:int(0.8*len(sentence_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rolled-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>triplet_seq</th>\n",
       "      <th>command</th>\n",
       "      <th>arg</th>\n",
       "      <th>resource</th>\n",
       "      <th>conditioned_seq</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[USE, TSKILLET, STOVE_MED]</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>use &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>move &lt;s&gt; remove from heat and drain the fat , ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>add the onion , celery and tomaotes .</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MED, COUNTER1]</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>move &lt;s&gt; add the onion , celery and tomaotes .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stir until well mixed .</td>\n",
       "      <td>[CHEF_CHECK, LTEXTURE, COUNTER1]</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>check &lt;s&gt; stir until well mixed .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>place a layer of shredded cabbage in the botto...</td>\n",
       "      <td>[USE, TBAKE_DISH, COUNTER2]</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>7</td>\n",
       "      <td>use &lt;s&gt; place a layer of shredded cabbage in t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>add the cabbage and cook the vegetable mixture...</td>\n",
       "      <td>[PUT, IsxiK2rPw, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the cabbage and cook the vegetable...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>then cover with hot water , season with walt a...</td>\n",
       "      <td>[USE, TFOIL, STOVE_MED]</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>11</td>\n",
       "      <td>use &lt;s&gt; then cover with hot water , season wit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>[PUT, IN2e0UIJI, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the rice and cook for 15 minutes l...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>[PUT, I_qDx9v7e, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the cheese , stir gently and turn ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>cover and let stand for 5 minutes before servi...</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MED, SERVE]</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>move &lt;s&gt; cover and let stand for 5 minutes bef...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_index                                          input_seq  \\\n",
       "0                 0                      brown meat in a big skillet .   \n",
       "1                 1      remove from heat and drain the fat , if any .   \n",
       "2                 2              add the onion , celery and tomaotes .   \n",
       "3                 3                            stir until well mixed .   \n",
       "4                 4  place a layer of shredded cabbage in the botto...   \n",
       "..              ...                                                ...   \n",
       "496             496  add the cabbage and cook the vegetable mixture...   \n",
       "497             497  then cover with hot water , season with walt a...   \n",
       "498             498      add the rice and cook for 15 minutes longer .   \n",
       "499             499  add the cheese , stir gently and turn off the ...   \n",
       "500             500  cover and let stand for 5 minutes before servi...   \n",
       "\n",
       "                                triplet_seq  command  arg  resource  \\\n",
       "0                [USE, TSKILLET, STOVE_MED]        3  143        11   \n",
       "1    [MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]        7   11        21   \n",
       "2      [MOVE_CONTENTS, STOVE_MED, COUNTER1]        7   11         6   \n",
       "3          [CHEF_CHECK, LTEXTURE, COUNTER1]        5  126         6   \n",
       "4               [USE, TBAKE_DISH, COUNTER2]        3  130         7   \n",
       "..                                      ...      ...  ...       ...   \n",
       "496             [PUT, IsxiK2rPw, STOVE_MED]        1  104        11   \n",
       "497                 [USE, TFOIL, STOVE_MED]        3  133        11   \n",
       "498             [PUT, IN2e0UIJI, STOVE_MED]        1   51        11   \n",
       "499             [PUT, I_qDx9v7e, STOVE_MED]        1   67        11   \n",
       "500       [MOVE_CONTENTS, STOVE_MED, SERVE]        7   11         0   \n",
       "\n",
       "                                       conditioned_seq  train  \n",
       "0                use <s> brown meat in a big skillet .   True  \n",
       "1    move <s> remove from heat and drain the fat , ...   True  \n",
       "2       move <s> add the onion , celery and tomaotes .   True  \n",
       "3                    check <s> stir until well mixed .   True  \n",
       "4    use <s> place a layer of shredded cabbage in t...  False  \n",
       "..                                                 ...    ...  \n",
       "496  put <s> add the cabbage and cook the vegetable...   True  \n",
       "497  use <s> then cover with hot water , season wit...  False  \n",
       "498  put <s> add the rice and cook for 15 minutes l...   True  \n",
       "499  put <s> add the cheese , stir gently and turn ...  False  \n",
       "500  move <s> cover and let stand for 5 minutes bef...   True  \n",
       "\n",
       "[501 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPLODE = False\n",
    "if EXPLODE:\n",
    "    df_prep = df.rename(columns={\"triplet_lst\":\"triplet_seq\"}).query(\"triplet_n<6\").explode(\"triplet_seq\")\n",
    "else:\n",
    "    df_prep = df.rename(columns={\"triplet_first\":\"triplet_seq\"})\n",
    "df_prep.index.name=\"sentence_index\"\n",
    "df_prep[\"command\"]  =  df_prep[\"triplet_seq\"].apply(lambda x: command2idx[x[0]])\n",
    "df_prep[\"arg\"]      =  df_prep[\"triplet_seq\"].apply(lambda x: arg2idx[x[1]])\n",
    "df_prep[\"resource\"] =  df_prep[\"triplet_seq\"].apply(lambda x: res2idx[x[2]])\n",
    "df_prep=df_prep[[\"input_seq\",\"triplet_seq\",  \"command\", \"arg\", \"resource\"]].reset_index()\n",
    "df_prep[\"conditioned_seq\"] = df_prep[\"command\"].map(commands) + \" <s> \" + df_prep[\"input_seq\"]\n",
    "df_prep[\"train\"]=df_prep[\"sentence_index\"].isin(train_idx)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nuclear-sociology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_prep[\"input_seq\"].str.split().str.len().plot.hist(density=True, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unlike-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=20\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "funky-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleInstructionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, text, train, target, max_length):\n",
    "        self.encodings = tokenizer(list(df[df[\"train\"]==train][text]), truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = list(df[df[\"train\"]==train][target])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-module",
   "metadata": {},
   "source": [
    "# Command Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dangerous-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "command_train_dataset = SingleInstructionDataset(df_prep, \"input_seq\", True,  \"command\", max_length)\n",
    "command_valid_dataset = SingleInstructionDataset(df_prep, \"input_seq\", False, \"command\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "welsh-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "command_names = list(command2idx.keys())\n",
    "command_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(command_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metropolitan-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 01:44, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.497800</td>\n",
       "      <td>1.402834</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>658.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.501300</td>\n",
       "      <td>2.456859</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>697.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>3.242757</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>706.586000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=0.6027081775665283, metrics={'train_runtime': 105.2501, 'train_samples_per_second': 7.126, 'total_flos': 179498568960000.0, 'epoch': 30.0, 'init_mem_cpu_alloc_delta': 7978581, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3083448, 'train_mem_gpu_alloc_delta': 2007216640, 'train_mem_cpu_peaked_delta': 154555523, 'train_mem_gpu_peaked_delta': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "command_trainer = Trainer(\n",
    "    model=command_model,                 # the instantiated Transformers model to be trained\n",
    "    args=command_training_args,                  # training arguments, defined above\n",
    "    train_dataset=command_train_dataset,         # training dataset\n",
    "    eval_dataset=command_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "command_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "specific-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_model.save_pretrained(\"command_model_first_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worth-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USE'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def command_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = command_model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return command_names[probs.argmax()]\n",
    "command_prediction(\"brown meat in large skillet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "discrete-government",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOVE_CONTENTS'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_prediction(\"add the onion , celery and tomaotes .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subject-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHEF_CHECK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_prediction(\"stir until well mixed .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rolled-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PUT'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_prediction(\"add sugar, lemon and spice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<s>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-dynamics",
   "metadata": {},
   "source": [
    "# Models for arg and resource\n",
    "## Arg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blocked-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/750 00:00 < 01:15, 9.89 it/s, Epoch 0.08/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-64095122d327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m# the callback that computes metrics of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0marg_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1459\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:29"
     ]
    }
   ],
   "source": [
    "arg_names = list(arg2idx.keys())\n",
    "arg_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(arg_names)).to(\"cuda\")\n",
    "arg_train_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", True,  \"arg\", max_length)\n",
    "arg_valid_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", False, \"arg\", max_length)\n",
    "arg_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    report_to=\"none\"\n",
    ")\n",
    "arg_trainer = Trainer(\n",
    "    model=arg_model,                 # the instantiated Transformers model to be trained\n",
    "    args=arg_training_args,                  # training arguments, defined above\n",
    "    train_dataset=arg_train_dataset,         # training dataset\n",
    "    eval_dataset=arg_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "arg_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_model.save_pretrained(\"arg_model_first_only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-affiliate",
   "metadata": {},
   "source": [
    "## Resource Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "moral-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "resource_names = list(res2idx.keys())\n",
    "resource_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(resource_names)).to(\"cuda\")\n",
    "resource_train_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", True,  \"resource\", max_length)\n",
    "resource_valid_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", False, \"resource\", max_length)\n",
    "resource_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "resource_trainer = Trainer(\n",
    "    model=resource_model,                 # the instantiated Transformers model to be trained\n",
    "    args=resource_training_args,                  # training arguments, defined above\n",
    "    train_dataset=resource_train_dataset,         # training dataset\n",
    "    eval_dataset=resource_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aging-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3', 4: 'LABEL_4', 5: 'LABEL_5', 6: 'LABEL_6', 7: 'LABEL_7', 8: 'LABEL_8', 9: 'LABEL_9', 10: 'LABEL_10', 11: 'LABEL_11', 12: 'LABEL_12', 13: 'LABEL_13', 14: 'LABEL_14', 15: 'LABEL_15', 16: 'LABEL_16', 17: 'LABEL_17', 18: 'LABEL_18', 19: 'LABEL_19', 20: 'LABEL_20', 21: 'LABEL_21', 22: 'LABEL_22', 23: 'LABEL_23', 24: 'LABEL_24', 25: 'LABEL_25', 26: 'LABEL_26', 27: 'LABEL_27', 28: 'LABEL_28', 29: 'LABEL_29', 30: 'LABEL_30', 31: 'LABEL_31', 32: 'LABEL_32', 33: 'LABEL_33', 34: 'LABEL_34', 35: 'LABEL_35', 36: 'LABEL_36', 37: 'LABEL_37', 38: 'LABEL_38', 39: 'LABEL_39', 40: 'LABEL_40', 41: 'LABEL_41', 42: 'LABEL_42', 43: 'LABEL_43', 44: 'LABEL_44', 45: 'LABEL_45', 46: 'LABEL_46', 47: 'LABEL_47', 48: 'LABEL_48', 49: 'LABEL_49', 50: 'LABEL_50', 51: 'LABEL_51', 52: 'LABEL_52', 53: 'LABEL_53', 54: 'LABEL_54', 55: 'LABEL_55', 56: 'LABEL_56', 57: 'LABEL_57', 58: 'LABEL_58', 59: 'LABEL_59', 60: 'LABEL_60', 61: 'LABEL_61', 62: 'LABEL_62', 63: 'LABEL_63', 64: 'LABEL_64', 65: 'LABEL_65', 66: 'LABEL_66', 67: 'LABEL_67', 68: 'LABEL_68', 69: 'LABEL_69', 70: 'LABEL_70', 71: 'LABEL_71', 72: 'LABEL_72', 73: 'LABEL_73', 74: 'LABEL_74', 75: 'LABEL_75', 76: 'LABEL_76', 77: 'LABEL_77', 78: 'LABEL_78', 79: 'LABEL_79', 80: 'LABEL_80', 81: 'LABEL_81', 82: 'LABEL_82', 83: 'LABEL_83', 84: 'LABEL_84', 85: 'LABEL_85', 86: 'LABEL_86', 87: 'LABEL_87', 88: 'LABEL_88', 89: 'LABEL_89', 90: 'LABEL_90', 91: 'LABEL_91', 92: 'LABEL_92', 93: 'LABEL_93', 94: 'LABEL_94', 95: 'LABEL_95', 96: 'LABEL_96', 97: 'LABEL_97', 98: 'LABEL_98', 99: 'LABEL_99', 100: 'LABEL_100', 101: 'LABEL_101', 102: 'LABEL_102', 103: 'LABEL_103', 104: 'LABEL_104', 105: 'LABEL_105', 106: 'LABEL_106', 107: 'LABEL_107', 108: 'LABEL_108', 109: 'LABEL_109', 110: 'LABEL_110', 111: 'LABEL_111', 112: 'LABEL_112', 113: 'LABEL_113', 114: 'LABEL_114', 115: 'LABEL_115', 116: 'LABEL_116', 117: 'LABEL_117', 118: 'LABEL_118', 119: 'LABEL_119', 120: 'LABEL_120', 121: 'LABEL_121', 122: 'LABEL_122', 123: 'LABEL_123', 124: 'LABEL_124', 125: 'LABEL_125', 126: 'LABEL_126', 127: 'LABEL_127', 128: 'LABEL_128', 129: 'LABEL_129', 130: 'LABEL_130', 131: 'LABEL_131', 132: 'LABEL_132', 133: 'LABEL_133', 134: 'LABEL_134', 135: 'LABEL_135', 136: 'LABEL_136', 137: 'LABEL_137', 138: 'LABEL_138', 139: 'LABEL_139', 140: 'LABEL_140', 141: 'LABEL_141', 142: 'LABEL_142', 143: 'LABEL_143'}\" for key \"id2label\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3, 'LABEL_4': 4, 'LABEL_5': 5, 'LABEL_6': 6, 'LABEL_7': 7, 'LABEL_8': 8, 'LABEL_9': 9, 'LABEL_10': 10, 'LABEL_11': 11, 'LABEL_12': 12, 'LABEL_13': 13, 'LABEL_14': 14, 'LABEL_15': 15, 'LABEL_16': 16, 'LABEL_17': 17, 'LABEL_18': 18, 'LABEL_19': 19, 'LABEL_20': 20, 'LABEL_21': 21, 'LABEL_22': 22, 'LABEL_23': 23, 'LABEL_24': 24, 'LABEL_25': 25, 'LABEL_26': 26, 'LABEL_27': 27, 'LABEL_28': 28, 'LABEL_29': 29, 'LABEL_30': 30, 'LABEL_31': 31, 'LABEL_32': 32, 'LABEL_33': 33, 'LABEL_34': 34, 'LABEL_35': 35, 'LABEL_36': 36, 'LABEL_37': 37, 'LABEL_38': 38, 'LABEL_39': 39, 'LABEL_40': 40, 'LABEL_41': 41, 'LABEL_42': 42, 'LABEL_43': 43, 'LABEL_44': 44, 'LABEL_45': 45, 'LABEL_46': 46, 'LABEL_47': 47, 'LABEL_48': 48, 'LABEL_49': 49, 'LABEL_50': 50, 'LABEL_51': 51, 'LABEL_52': 52, 'LABEL_53': 53, 'LABEL_54': 54, 'LABEL_55': 55, 'LABEL_56': 56, 'LABEL_57': 57, 'LABEL_58': 58, 'LABEL_59': 59, 'LABEL_60': 60, 'LABEL_61': 61, 'LABEL_62': 62, 'LABEL_63': 63, 'LABEL_64': 64, 'LABEL_65': 65, 'LABEL_66': 66, 'LABEL_67': 67, 'LABEL_68': 68, 'LABEL_69': 69, 'LABEL_70': 70, 'LABEL_71': 71, 'LABEL_72': 72, 'LABEL_73': 73, 'LABEL_74': 74, 'LABEL_75': 75, 'LABEL_76': 76, 'LABEL_77': 77, 'LABEL_78': 78, 'LABEL_79': 79, 'LABEL_80': 80, 'LABEL_81': 81, 'LABEL_82': 82, 'LABEL_83': 83, 'LABEL_84': 84, 'LABEL_85': 85, 'LABEL_86': 86, 'LABEL_87': 87, 'LABEL_88': 88, 'LABEL_89': 89, 'LABEL_90': 90, 'LABEL_91': 91, 'LABEL_92': 92, 'LABEL_93': 93, 'LABEL_94': 94, 'LABEL_95': 95, 'LABEL_96': 96, 'LABEL_97': 97, 'LABEL_98': 98, 'LABEL_99': 99, 'LABEL_100': 100, 'LABEL_101': 101, 'LABEL_102': 102, 'LABEL_103': 103, 'LABEL_104': 104, 'LABEL_105': 105, 'LABEL_106': 106, 'LABEL_107': 107, 'LABEL_108': 108, 'LABEL_109': 109, 'LABEL_110': 110, 'LABEL_111': 111, 'LABEL_112': 112, 'LABEL_113': 113, 'LABEL_114': 114, 'LABEL_115': 115, 'LABEL_116': 116, 'LABEL_117': 117, 'LABEL_118': 118, 'LABEL_119': 119, 'LABEL_120': 120, 'LABEL_121': 121, 'LABEL_122': 122, 'LABEL_123': 123, 'LABEL_124': 124, 'LABEL_125': 125, 'LABEL_126': 126, 'LABEL_127': 127, 'LABEL_128': 128, 'LABEL_129': 129, 'LABEL_130': 130, 'LABEL_131': 131, 'LABEL_132': 132, 'LABEL_133': 133, 'LABEL_134': 134, 'LABEL_135': 135, 'LABEL_136': 136, 'LABEL_137': 137, 'LABEL_138': 138, 'LABEL_139': 139, 'LABEL_140': 140, 'LABEL_141': 141, 'LABEL_142': 142, 'LABEL_143': 143}\" for key \"label2id\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 01:40, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.339400</td>\n",
       "      <td>2.512432</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>699.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>2.654374</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>728.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>3.005630</td>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>725.256000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=1.4422149353027345, metrics={'train_runtime': 101.364, 'train_samples_per_second': 7.399, 'total_flos': 179649169920000.0, 'epoch': 30.0, 'init_mem_cpu_alloc_delta': 7980534, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3110044, 'train_mem_gpu_alloc_delta': 2008889856, 'train_mem_cpu_peaked_delta': 154524435, 'train_mem_gpu_peaked_delta': 0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "related-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_model.save_pretrained(\"resource_model_first_only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-marina",
   "metadata": {},
   "source": [
    "# Bag of words model for ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "coordinated-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_prep.query(\"train\")[\"conditioned_seq\"]\n",
    "X_test = df_prep.query(\"not train\")[\"conditioned_seq\"]\n",
    "y_train = df_prep.query(\"train\")[\"arg\"]\n",
    "y_test = df_prep.query(\"not train\")[\"arg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "determined-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37623762376237624\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy as clone\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class ConditionedTextClassifier(ClassifierMixin):\n",
    "    def __init__(self, conditions, model, condition_sep=' <s> '):\n",
    "        self.condition_sep=condition_sep\n",
    "        self.conditions = {}\n",
    "        for c in conditions:\n",
    "            self.conditions[c] = clone(model)\n",
    "    def _filter_condition(self, X,y=None,c=None):\n",
    "        if y is None:\n",
    "            y = [None]*len(X)\n",
    "        if c is None:\n",
    "            raise SyntaxError(\"condition cannot be None\")\n",
    "        IXY = [s.split(self.condition_sep, 1) for s in X]\n",
    "        IXY = [(yy[0], xx[1], yy[1]) for xx,yy in zip(IXY,enumerate(y)) if xx[0]==c]\n",
    "        if len(IXY)==0:\n",
    "            return [],[],[]\n",
    "        ind, X,y = zip(*IXY)\n",
    "        return ind, X, y\n",
    "    def fit(self, X, y):\n",
    "        for c in self.conditions:\n",
    "            ind_c, X_c, y_c = self._filter_condition(X,y,c)\n",
    "            if len(X_c)>0:\n",
    "                self.conditions[c].fit(X_c, y_c)\n",
    "    def predict(self, X):\n",
    "        ret = []\n",
    "        for c in self.conditions:\n",
    "            ind_c, X_c, y_c = self._filter_condition(X, c=c)\n",
    "            if len(X_c)>0:\n",
    "                y_c = self.conditions[c].predict(X_c)\n",
    "                ret.extend(list(zip(ind_c, y_c)))\n",
    "        ret = [y for i,y in sorted(ret)]\n",
    "        return ret\n",
    "    \n",
    "base_model = Pipeline([\n",
    "    (\"vec\", CountVectorizer(min_df=1, max_df=0.7, binary=True)),\n",
    "#     (\"vec\", TfidfVectorizer(min_df=1, max_df=0.7)),\n",
    "#     (\"model\", LogisticRegression()),\n",
    "    (\"model\", LogisticRegression(dual=True, solver='liblinear')),\n",
    "])\n",
    "\n",
    "arg_model = ConditionedTextClassifier(list(commands.values()), base_model)\n",
    "arg_model.fit(X_train, y_train)\n",
    "y_pred = arg_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ruled-gauge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2376237623762376\n"
     ]
    }
   ],
   "source": [
    "# arg_model = Pipeline([\n",
    "# #     (\"vec\", CountVectorizer(min_df=1, max_df=0.7, binary=True)),\n",
    "#     (\"vec\", TfidfVectorizer(min_df=1, max_df=0.7)),\n",
    "# #     (\"model\", LogisticRegression()),\n",
    "#     (\"model\", LogisticRegression(dual=True, solver='liblinear')),\n",
    "# ])\n",
    "# arg_model.fit(X_train, y_train)\n",
    "# y_pred = arg_model.predict(X_test)\n",
    "# print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-trinidad",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "elegant-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_names = list(res2idx.keys())\n",
    "resource_model = RobertaForSequenceClassification.from_pretrained(\"resource_model_first_only\", num_labels=len(resource_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "distinct-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_names = list(command2idx.keys())\n",
    "command_model = RobertaForSequenceClassification.from_pretrained(\"command_model_first_only\", num_labels=len(command_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "characteristic-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    # COMMAND MODEL\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = command_model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    cmd_idx = probs.argmax()\n",
    "    command = command_names[cmd_idx]\n",
    "    #RESOURCE MODEL\n",
    "    text = commands[int(cmd_idx.to('cpu'))] + \" </s> \" + text\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = resource_model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    res_idx = probs.argmax()\n",
    "    res = resource_names[res_idx]\n",
    "    arg = idx2arg[arg_model.predict([text])[0]]\n",
    "\n",
    "    return (command, arg, res)\n",
    "\n",
    "def pred_command(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = command_model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    return int(probs.argmax())\n",
    "\n",
    "def pred_resource(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = resource_model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    ret = int(probs.argmax())\n",
    "    if idx2arg[ret][-1].isdigit():\n",
    "        ret=res2idx[idx2arg[ret][:-1]+'1']\n",
    "    return ret\n",
    "\n",
    "def pred_arg(text):\n",
    "    return arg_model.predict([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "industrial-start",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('USE', 'COUNTER1', 'STOVE_MEDHI')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"use skillet to fry chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "respected-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"pred_command\"] = df_prep[\"input_seq\"].apply(pred_command)\n",
    "df_prep[\"pred_resource\"] = df_prep[\"conditioned_seq\"].apply(pred_resource)\n",
    "df_prep[\"pred_arg\"] = df_prep[\"conditioned_seq\"].apply(pred_arg)\n",
    "df_prep[\"combined\"]=df_prep.apply(lambda r: f\"{r['command']}~{r['arg']}~{r['resource']}\",axis=1)\n",
    "df_prep[\"pred_combined\"]=df_prep.apply(lambda r: f\"{r['pred_command']}~{r['pred_arg']}~{r['pred_resource']}\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "impaired-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"triplet_seq\"] = df_prep[\"triplet_seq\"].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "lovely-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(df_prep[\"triplet_seq\"].apply(str), df_prep[\"pred\"].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "banned-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_prep.query(\"not train\")\n",
    "# accuracy_score(df_test[\"triplet_seq\"].apply(str), df_test[\"pred\"].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "concrete-verse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>triplet_seq</th>\n",
       "      <th>command</th>\n",
       "      <th>arg</th>\n",
       "      <th>resource</th>\n",
       "      <th>conditioned_seq</th>\n",
       "      <th>train</th>\n",
       "      <th>pred_command</th>\n",
       "      <th>pred_resource</th>\n",
       "      <th>pred_arg</th>\n",
       "      <th>combined</th>\n",
       "      <th>pred_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>place a layer of shredded cabbage in the botto...</td>\n",
       "      <td>(USE, TBAKE_DISH, COUNTER2)</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>7</td>\n",
       "      <td>use &lt;s&gt; place a layer of shredded cabbage in t...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>130</td>\n",
       "      <td>3~130~7</td>\n",
       "      <td>3~130~6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>combine meat , spinach , cheese and seasonings .</td>\n",
       "      <td>(MOVE_CONTENTS, STOVE_MEDLOW, STOVE_MED)</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>move &lt;s&gt; combine meat , spinach , cheese and s...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>7~10~11</td>\n",
       "      <td>7~6~11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>in a food processor , puree the chopped tomato...</td>\n",
       "      <td>(MOVE_CONTENTS, APPL_PROCESSOR, COUNTER1)</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>move &lt;s&gt; in a food processor , puree the chopp...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7~3~6</td>\n",
       "      <td>7~11~6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>process on medium speed until smooth .</td>\n",
       "      <td>(CHEF_CHECK, LTEXTURE, APPL_BLEND)</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>check &lt;s&gt; process on medium speed until smooth .</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>5~126~4</td>\n",
       "      <td>7~126~4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>remove cover and continue baking for 10 minute...</td>\n",
       "      <td>(STOP_USING, TFOIL, OVEN_MED)</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>unuse &lt;s&gt; remove cover and continue baking for...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>4~133~15</td>\n",
       "      <td>4~140~15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>serve hot .</td>\n",
       "      <td>(MOVE_CONTENTS, COUNTER1, SERVE)</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>move &lt;s&gt; serve hot .</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7~6~0</td>\n",
       "      <td>7~6~0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>in large skillet , over medium heat , melt mar...</td>\n",
       "      <td>(USE, TSKILLET, STOVE_MED)</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>use &lt;s&gt; in large skillet , over medium heat , ...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>3~143~11</td>\n",
       "      <td>3~143~11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>stir in corn , egg beater with cheese , parsle...</td>\n",
       "      <td>(PUT, IrXTUISnn, STOVE_MED)</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; stir in corn , egg beater with cheese ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1~101~11</td>\n",
       "      <td>1~101~11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>then cover with hot water , season with walt a...</td>\n",
       "      <td>(USE, TFOIL, STOVE_MED)</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>11</td>\n",
       "      <td>use &lt;s&gt; then cover with hot water , season wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>137</td>\n",
       "      <td>3~133~11</td>\n",
       "      <td>3~137~11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>(PUT, I_qDx9v7e, STOVE_MED)</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the cheese , stir gently and turn ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>1~67~11</td>\n",
       "      <td>1~51~11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_index                                          input_seq  \\\n",
       "4                 4  place a layer of shredded cabbage in the botto...   \n",
       "11               11   combine meat , spinach , cheese and seasonings .   \n",
       "17               17  in a food processor , puree the chopped tomato...   \n",
       "22               22             process on medium speed until smooth .   \n",
       "25               25  remove cover and continue baking for 10 minute...   \n",
       "..              ...                                                ...   \n",
       "465             465                                        serve hot .   \n",
       "482             482  in large skillet , over medium heat , melt mar...   \n",
       "485             485  stir in corn , egg beater with cheese , parsle...   \n",
       "497             497  then cover with hot water , season with walt a...   \n",
       "499             499  add the cheese , stir gently and turn off the ...   \n",
       "\n",
       "                                   triplet_seq  command  arg  resource  \\\n",
       "4                  (USE, TBAKE_DISH, COUNTER2)        3  130         7   \n",
       "11    (MOVE_CONTENTS, STOVE_MEDLOW, STOVE_MED)        7   10        11   \n",
       "17   (MOVE_CONTENTS, APPL_PROCESSOR, COUNTER1)        7    3         6   \n",
       "22          (CHEF_CHECK, LTEXTURE, APPL_BLEND)        5  126         4   \n",
       "25               (STOP_USING, TFOIL, OVEN_MED)        4  133        15   \n",
       "..                                         ...      ...  ...       ...   \n",
       "465           (MOVE_CONTENTS, COUNTER1, SERVE)        7    6         0   \n",
       "482                 (USE, TSKILLET, STOVE_MED)        3  143        11   \n",
       "485                (PUT, IrXTUISnn, STOVE_MED)        1  101        11   \n",
       "497                    (USE, TFOIL, STOVE_MED)        3  133        11   \n",
       "499                (PUT, I_qDx9v7e, STOVE_MED)        1   67        11   \n",
       "\n",
       "                                       conditioned_seq  train  pred_command  \\\n",
       "4    use <s> place a layer of shredded cabbage in t...  False             3   \n",
       "11   move <s> combine meat , spinach , cheese and s...  False             7   \n",
       "17   move <s> in a food processor , puree the chopp...  False             7   \n",
       "22    check <s> process on medium speed until smooth .  False             7   \n",
       "25   unuse <s> remove cover and continue baking for...  False             4   \n",
       "..                                                 ...    ...           ...   \n",
       "465                               move <s> serve hot .  False             7   \n",
       "482  use <s> in large skillet , over medium heat , ...  False             3   \n",
       "485  put <s> stir in corn , egg beater with cheese ...  False             1   \n",
       "497  use <s> then cover with hot water , season wit...  False             3   \n",
       "499  put <s> add the cheese , stir gently and turn ...  False             1   \n",
       "\n",
       "     pred_resource  pred_arg  combined pred_combined  \n",
       "4                6       130   3~130~7       3~130~6  \n",
       "11              11         6   7~10~11        7~6~11  \n",
       "17               6        11     7~3~6        7~11~6  \n",
       "22               4       126   5~126~4       7~126~4  \n",
       "25              15       140  4~133~15      4~140~15  \n",
       "..             ...       ...       ...           ...  \n",
       "465              0         6     7~6~0         7~6~0  \n",
       "482             11       143  3~143~11      3~143~11  \n",
       "485             11       101  1~101~11      1~101~11  \n",
       "497             11       137  3~133~11      3~137~11  \n",
       "499             11        51   1~67~11       1~51~11  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "finished-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================>command<====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.92      0.92        24\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.80      0.95      0.87        21\n",
      "           4       1.00      0.75      0.86         4\n",
      "           5       1.00      0.50      0.67        10\n",
      "           7       0.86      0.90      0.88        41\n",
      "\n",
      "    accuracy                           0.87       101\n",
      "   macro avg       0.93      0.84      0.87       101\n",
      "weighted avg       0.88      0.87      0.87       101\n",
      "\n",
      "====================>resource<====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           2       0.50      1.00      0.67         1\n",
      "           4       1.00      1.00      1.00         4\n",
      "           6       0.85      0.91      0.88        32\n",
      "           7       0.00      0.00      0.00         4\n",
      "           9       0.92      1.00      0.96        11\n",
      "          10       0.80      0.57      0.67         7\n",
      "          11       0.90      1.00      0.95        18\n",
      "          12       0.00      0.00      0.00         0\n",
      "          15       0.86      0.86      0.86         7\n",
      "          16       0.75      0.75      0.75         4\n",
      "          18       1.00      1.00      1.00         4\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.86       101\n",
      "   macro avg       0.68      0.68      0.67       101\n",
      "weighted avg       0.84      0.86      0.85       101\n",
      "\n",
      "====================>arg<====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           6       0.49      0.89      0.63        19\n",
      "           7       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.20      0.17      0.18         6\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         1\n",
      "          24       1.00      0.50      0.67         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          71       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         1\n",
      "         101       0.50      1.00      0.67         1\n",
      "         103       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.33      0.67      0.44         3\n",
      "         116       0.00      0.00      0.00         4\n",
      "         118       1.00      0.50      0.67         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         126       1.00      1.00      1.00         2\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.57      1.00      0.73         4\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.50      0.50      0.50         2\n",
      "         131       0.43      0.43      0.43         7\n",
      "         133       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         3\n",
      "         137       0.30      1.00      0.46         3\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.33      1.00      0.50         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         143       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.38       101\n",
      "   macro avg       0.15      0.17      0.14       101\n",
      "weighted avg       0.29      0.38      0.30       101\n",
      "\n",
      "====================>combined<====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    1~101~11       1.00      1.00      1.00         1\n",
      "     1~101~6       0.00      0.00      0.00         0\n",
      "    1~103~15       0.00      0.00      0.00         0\n",
      "     1~103~6       0.00      0.00      0.00         0\n",
      "    1~109~15       0.00      0.00      0.00         1\n",
      "     1~113~6       0.00      0.00      0.00         1\n",
      "     1~114~6       0.00      0.00      0.00         1\n",
      "    1~115~11       0.00      0.00      0.00         0\n",
      "     1~115~4       0.00      0.00      0.00         1\n",
      "     1~115~6       0.50      1.00      0.67         2\n",
      "    1~116~11       0.00      0.00      0.00         2\n",
      "     1~116~6       0.00      0.00      0.00         1\n",
      "     1~116~7       0.00      0.00      0.00         1\n",
      "     1~128~6       0.00      0.00      0.00         0\n",
      "     1~24~10       0.00      0.00      0.00         0\n",
      "     1~24~11       0.00      0.00      0.00         1\n",
      "      1~24~6       0.00      0.00      0.00         1\n",
      "      1~25~4       0.00      0.00      0.00         1\n",
      "      1~31~6       0.00      0.00      0.00         1\n",
      "      1~38~4       0.00      0.00      0.00         0\n",
      "     1~40~11       0.00      0.00      0.00         1\n",
      "      1~40~2       0.00      0.00      0.00         0\n",
      "      1~40~4       0.00      0.00      0.00         0\n",
      "      1~42~6       0.00      0.00      0.00         1\n",
      "      1~48~6       0.00      0.00      0.00         1\n",
      "     1~51~11       0.00      0.00      0.00         0\n",
      "      1~57~6       0.00      0.00      0.00         1\n",
      "     1~58~20       0.00      0.00      0.00         1\n",
      "     1~59~11       0.00      0.00      0.00         0\n",
      "     1~67~11       0.00      0.00      0.00         1\n",
      "     1~68~11       0.00      0.00      0.00         0\n",
      "      1~6~11       0.00      0.00      0.00         0\n",
      "     1~71~16       0.00      0.00      0.00         1\n",
      "     1~79~11       0.00      0.00      0.00         1\n",
      "      1~86~2       0.00      0.00      0.00         1\n",
      "     1~93~16       0.00      0.00      0.00         0\n",
      "      1~93~2       0.00      0.00      0.00         0\n",
      "      2~51~6       0.00      0.00      0.00         0\n",
      "      2~93~6       0.00      0.00      0.00         1\n",
      "     3~116~6       0.00      0.00      0.00         0\n",
      "    3~128~11       0.00      0.00      0.00         0\n",
      "     3~129~6       0.00      0.00      0.00         1\n",
      "    3~130~11       0.00      0.00      0.00         1\n",
      "     3~130~6       0.00      0.00      0.00         0\n",
      "     3~130~7       0.00      0.00      0.00         1\n",
      "    3~131~11       0.00      0.00      0.00         0\n",
      "    3~131~15       0.00      0.00      0.00         1\n",
      "     3~131~6       0.33      0.50      0.40         4\n",
      "     3~131~7       0.00      0.00      0.00         2\n",
      "    3~133~11       0.00      0.00      0.00         1\n",
      "     3~136~9       0.00      0.00      0.00         1\n",
      "    3~137~11       0.25      0.50      0.33         2\n",
      "    3~137~15       0.00      0.00      0.00         0\n",
      "     3~137~6       0.00      0.00      0.00         1\n",
      "     3~137~9       0.00      0.00      0.00         0\n",
      "     3~140~6       1.00      1.00      1.00         1\n",
      "     3~141~6       0.00      0.00      0.00         1\n",
      "    3~143~11       1.00      0.50      0.67         2\n",
      "     3~143~6       0.00      0.00      0.00         1\n",
      "     3~143~9       0.00      0.00      0.00         1\n",
      "      3~6~12       0.00      0.00      0.00         0\n",
      "      3~6~15       0.00      0.00      0.00         0\n",
      "       3~6~6       0.00      0.00      0.00         0\n",
      "    4~133~15       0.00      0.00      0.00         1\n",
      "     4~133~6       0.00      0.00      0.00         0\n",
      "     4~136~6       0.00      0.00      0.00         1\n",
      "     4~136~9       0.00      0.00      0.00         1\n",
      "     4~139~6       0.00      0.00      0.00         1\n",
      "    4~140~15       0.00      0.00      0.00         0\n",
      "    5~118~10       1.00      1.00      1.00         1\n",
      "    5~118~11       0.00      0.00      0.00         1\n",
      "     5~122~6       0.00      0.00      0.00         1\n",
      "     5~126~4       0.00      0.00      0.00         1\n",
      "     5~126~6       1.00      1.00      1.00         1\n",
      "     5~127~9       0.00      0.00      0.00         1\n",
      "    5~128~10       0.00      0.00      0.00         1\n",
      "    5~128~11       0.00      0.00      0.00         0\n",
      "    5~128~18       1.00      1.00      1.00         1\n",
      "     5~128~6       0.00      0.00      0.00         1\n",
      "     5~128~9       0.00      0.00      0.00         1\n",
      "     7~10~11       0.00      0.00      0.00         1\n",
      "      7~11~0       0.00      0.00      0.00         2\n",
      "     7~11~10       0.00      0.00      0.00         1\n",
      "     7~11~11       0.00      0.00      0.00         0\n",
      "     7~11~18       0.00      0.00      0.00         0\n",
      "     7~11~21       0.00      0.00      0.00         1\n",
      "      7~11~6       0.50      1.00      0.67         1\n",
      "      7~11~9       0.00      0.00      0.00         1\n",
      "     7~126~4       0.00      0.00      0.00         0\n",
      "     7~128~9       0.00      0.00      0.00         0\n",
      "     7~12~21       0.00      0.00      0.00         1\n",
      "    7~137~11       0.00      0.00      0.00         0\n",
      "     7~13~10       0.00      0.00      0.00         1\n",
      "      7~13~6       0.00      0.00      0.00         1\n",
      "     7~140~9       0.00      0.00      0.00         0\n",
      "      7~15~4       0.00      0.00      0.00         1\n",
      "      7~16~6       0.00      0.00      0.00         1\n",
      "      7~18~6       0.00      0.00      0.00         1\n",
      "      7~2~10       0.00      0.00      0.00         1\n",
      "      7~2~18       0.00      0.00      0.00         1\n",
      "       7~3~6       0.00      0.00      0.00         1\n",
      "     7~41~16       0.00      0.00      0.00         0\n",
      "      7~4~10       0.00      0.00      0.00         1\n",
      "      7~4~15       0.00      0.00      0.00         1\n",
      "      7~4~16       0.00      0.00      0.00         1\n",
      "      7~4~18       0.00      0.00      0.00         1\n",
      "       7~4~6       0.00      0.00      0.00         1\n",
      "       7~6~0       0.67      1.00      0.80         4\n",
      "      7~6~10       0.00      0.00      0.00         1\n",
      "      7~6~11       0.50      0.33      0.40         3\n",
      "      7~6~12       0.00      0.00      0.00         0\n",
      "      7~6~15       1.00      1.00      1.00         3\n",
      "      7~6~16       0.50      0.50      0.50         2\n",
      "      7~6~18       0.50      1.00      0.67         1\n",
      "       7~6~4       0.00      0.00      0.00         0\n",
      "       7~6~6       0.00      0.00      0.00         0\n",
      "       7~6~9       0.71      1.00      0.83         5\n",
      "       7~7~6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27       101\n",
      "   macro avg       0.10      0.11      0.10       101\n",
      "weighted avg       0.22      0.27      0.24       101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for c in [\"command\", \"resource\", \"arg\", \"combined\"]:\n",
    "    print (\"=\"*20 + \">\" +  c + \"<\"+ \"=\"*20)\n",
    "    print (classification_report(df_test[c], df_test[\"pred_\"+c]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-reference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-advice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
