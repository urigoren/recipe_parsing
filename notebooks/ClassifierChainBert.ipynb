{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resistant-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, collections, itertools,random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, classification_report\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "placed-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-anthropology",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organized-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = {\n",
    "    0:\"Nothing\",\n",
    "    1:\"Put\",\n",
    "    2:\"Remove\",\n",
    "    3:\"Use\",\n",
    "    4:\"Unuse\",\n",
    "    5:\"Check\",\n",
    "    6:\"Do\",\n",
    "    7:\"Move\",\n",
    "}\n",
    "command2idx = {\n",
    "        \"NOOP\": 0,\n",
    "        \"PUT\": 1,\n",
    "        \"REMOVE\": 2,\n",
    "        \"USE\": 3,\n",
    "        \"STOP_USING\": 4,\n",
    "        \"CHEF_CHECK\": 5,\n",
    "        \"CHEF_DO\": 6,\n",
    "        \"MOVE_CONTENTS\": 7,\n",
    "    }\n",
    "with open(\"../data/ingredients.json\", 'r') as f:\n",
    "    ingredients = dict(json.load(f))\n",
    "with open(\"../data/resources.json\", 'r') as f:\n",
    "    resources = json.load(f)\n",
    "    resources = [(r[\"id\"], r[\"name\"]) for r in resources if 'children' not in r] + [(r[\"id\"], lst[\"name\"]+'/'+r[\"name\"]) for lst in resources if 'children' in lst for r in lst[\"children\"]]\n",
    "    resources = {k:v for k,v in resources if not k.startswith(\"VALID_\")}\n",
    "    res2idx = {k:i for i,k in enumerate(resources.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriental-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg2idx = res2idx\n",
    "k=len(arg2idx)+1\n",
    "with open(\"../data/arg2idx.json\", 'r') as f:\n",
    "    for w, i in json.load(f).items():\n",
    "        arg2idx[w.replace('-', '_')] = k\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-gazette",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "saved-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_seq</th>\n",
       "      <th>output_seq</th>\n",
       "      <th>triplet_n</th>\n",
       "      <th>triplet_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>stir in mustard and beef broth .</td>\n",
       "      <td>MOVE_CONTENTS STOVE_MEDLOW APPL_BLEND MOVE_CON...</td>\n",
       "      <td>6</td>\n",
       "      <td>[[MOVE_CONTENTS, STOVE_MEDLOW, APPL_BLEND], [M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>before serving , stir in dill .</td>\n",
       "      <td>PUT IlNbCt_kq STOVE_MED</td>\n",
       "      <td>1</td>\n",
       "      <td>[[PUT, IlNbCt_kq, STOVE_MED]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>place tomatoes , onions , red peppers , tomato...</td>\n",
       "      <td>PUT IaGLvtAKO APPL_BLEND PUT IqSsJ8Pki APPL_BL...</td>\n",
       "      <td>8</td>\n",
       "      <td>[[PUT, IaGLvtAKO, APPL_BLEND], [PUT, IqSsJ8Pki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>stir in parsley and salt ;</td>\n",
       "      <td>USE TSPATULA STOVE_MEDLOW PUT IzrIHcuDJ STOVE_...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[USE, TSPATULA, STOVE_MEDLOW], [PUT, IzrIHcuD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>sprinkle with cheese over top .</td>\n",
       "      <td>REMOVE I10_d4pRP STOVE_MEDLOW REMOVE Iz0wiMjVJ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[REMOVE, I10_d4pRP, STOVE_MEDLOW], [REMOVE, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cut unpeeled potatoes and zucchini into 1/2 ''...</td>\n",
       "      <td>USE TGRATER COUNTER1 PUT IjuICeYOR COUNTER1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[USE, TGRATER, COUNTER1], [PUT, IjuICeYOR, CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>add the potatoes and stock ( or water ) and si...</td>\n",
       "      <td>PUT IjuICeYOR STOVE_MED PUT IlGA3C7DK STOVE_ME...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[PUT, IjuICeYOR, STOVE_MED], [PUT, IlGA3C7DK,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>reduce heat to low and cook , covered , for 6 ...</td>\n",
       "      <td>MOVE_CONTENTS STOVE_MEDHI STOVE_LOW MOVE_CONTE...</td>\n",
       "      <td>6</td>\n",
       "      <td>[[MOVE_CONTENTS, STOVE_MEDHI, STOVE_LOW], [MOV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>add potatoes and stir fry for 1 minute .</td>\n",
       "      <td>USE TSKILLET STOVE_MEDHI PUT Ixa8FQ0B6 STOVE_M...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[USE, TSKILLET, STOVE_MEDHI], [PUT, Ixa8FQ0B6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>brush with oil and lay on rack in roasting pan .</td>\n",
       "      <td>MOVE_CONTENTS APPL_BLEND SERVE MOVE_CONTENTS C...</td>\n",
       "      <td>4</td>\n",
       "      <td>[[MOVE_CONTENTS, APPL_BLEND, SERVE], [MOVE_CON...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_seq  \\\n",
       "84                    stir in mustard and beef broth .   \n",
       "397                    before serving , stir in dill .   \n",
       "21   place tomatoes , onions , red peppers , tomato...   \n",
       "454                         stir in parsley and salt ;   \n",
       "352                    sprinkle with cheese over top .   \n",
       "488  cut unpeeled potatoes and zucchini into 1/2 ''...   \n",
       "394  add the potatoes and stock ( or water ) and si...   \n",
       "74   reduce heat to low and cook , covered , for 6 ...   \n",
       "490           add potatoes and stir fry for 1 minute .   \n",
       "447   brush with oil and lay on rack in roasting pan .   \n",
       "\n",
       "                                            output_seq  triplet_n  \\\n",
       "84   MOVE_CONTENTS STOVE_MEDLOW APPL_BLEND MOVE_CON...          6   \n",
       "397                            PUT IlNbCt_kq STOVE_MED          1   \n",
       "21   PUT IaGLvtAKO APPL_BLEND PUT IqSsJ8Pki APPL_BL...          8   \n",
       "454  USE TSPATULA STOVE_MEDLOW PUT IzrIHcuDJ STOVE_...          3   \n",
       "352  REMOVE I10_d4pRP STOVE_MEDLOW REMOVE Iz0wiMjVJ...          3   \n",
       "488        USE TGRATER COUNTER1 PUT IjuICeYOR COUNTER1          2   \n",
       "394  PUT IjuICeYOR STOVE_MED PUT IlGA3C7DK STOVE_ME...          3   \n",
       "74   MOVE_CONTENTS STOVE_MEDHI STOVE_LOW MOVE_CONTE...          6   \n",
       "490  USE TSKILLET STOVE_MEDHI PUT Ixa8FQ0B6 STOVE_M...          2   \n",
       "447  MOVE_CONTENTS APPL_BLEND SERVE MOVE_CONTENTS C...          4   \n",
       "\n",
       "                                           triplet_seq  \n",
       "84   [[MOVE_CONTENTS, STOVE_MEDLOW, APPL_BLEND], [M...  \n",
       "397                      [[PUT, IlNbCt_kq, STOVE_MED]]  \n",
       "21   [[PUT, IaGLvtAKO, APPL_BLEND], [PUT, IqSsJ8Pki...  \n",
       "454  [[USE, TSPATULA, STOVE_MEDLOW], [PUT, IzrIHcuD...  \n",
       "352  [[REMOVE, I10_d4pRP, STOVE_MEDLOW], [REMOVE, I...  \n",
       "488  [[USE, TGRATER, COUNTER1], [PUT, IjuICeYOR, CO...  \n",
       "394  [[PUT, IjuICeYOR, STOVE_MED], [PUT, IlGA3C7DK,...  \n",
       "74   [[MOVE_CONTENTS, STOVE_MEDHI, STOVE_LOW], [MOV...  \n",
       "490  [[USE, TSKILLET, STOVE_MEDHI], [PUT, Ixa8FQ0B6...  \n",
       "447  [[MOVE_CONTENTS, APPL_BLEND, SERVE], [MOVE_CON...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def triplet_split(s):\n",
    "    ret = []\n",
    "    s=s.split()\n",
    "    for i,t in enumerate(s):\n",
    "        if i%3==0:\n",
    "            ret.append([])\n",
    "        ret[-1].append(t)\n",
    "    return ret\n",
    "df = pd.read_csv(\"seq2seq_4335716.csv\")\n",
    "df[\"triplet_n\"] = df[\"output_seq\"].str.split().str.len()//3\n",
    "df[\"triplet_seq\"] = df[\"output_seq\"].apply(triplet_split)\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overhead-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"triplet_n\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "awful-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_idx = list(df.index)\n",
    "random.shuffle(sentence_idx)\n",
    "train_idx = sentence_idx[:int(0.8*len(sentence_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "major-stadium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>command</th>\n",
       "      <th>arg</th>\n",
       "      <th>resource</th>\n",
       "      <th>conditioned_seq</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>Use&lt;s&gt;brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Put&lt;s&gt;brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>Move&lt;s&gt;remove from heat and drain the fat , if...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "      <td>Use&lt;s&gt;remove from heat and drain the fat , if ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>497</td>\n",
       "      <td>then cover with hot water , season with walt a...</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;then cover with hot water , season wit...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>Put&lt;s&gt;add the rice and cook for 15 minutes lon...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;add the rice and cook for 15 minutes l...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>Put&lt;s&gt;add the cheese , stir gently and turn of...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;add the cheese , stir gently and turn ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_index                                          input_seq  \\\n",
       "0                  0                      brown meat in a big skillet .   \n",
       "1                  0                      brown meat in a big skillet .   \n",
       "2                  0                      brown meat in a big skillet .   \n",
       "3                  1      remove from heat and drain the fat , if any .   \n",
       "4                  1      remove from heat and drain the fat , if any .   \n",
       "...              ...                                                ...   \n",
       "1223             497  then cover with hot water , season with walt a...   \n",
       "1224             498      add the rice and cook for 15 minutes longer .   \n",
       "1225             498      add the rice and cook for 15 minutes longer .   \n",
       "1226             499  add the cheese , stir gently and turn off the ...   \n",
       "1227             499  add the cheese , stir gently and turn off the ...   \n",
       "\n",
       "      command  arg  resource  \\\n",
       "0           3  143        11   \n",
       "1           1   52        11   \n",
       "2           5  119        11   \n",
       "3           7   11        21   \n",
       "4           3  143        21   \n",
       "...       ...  ...       ...   \n",
       "1223        5  128        11   \n",
       "1224        1   51        11   \n",
       "1225        5  128        11   \n",
       "1226        1   67        11   \n",
       "1227        5  128        11   \n",
       "\n",
       "                                        conditioned_seq  train  \n",
       "0                   Use<s>brown meat in a big skillet .   True  \n",
       "1                   Put<s>brown meat in a big skillet .   True  \n",
       "2                 Check<s>brown meat in a big skillet .   True  \n",
       "3     Move<s>remove from heat and drain the fat , if...   True  \n",
       "4     Use<s>remove from heat and drain the fat , if ...   True  \n",
       "...                                                 ...    ...  \n",
       "1223  Check<s>then cover with hot water , season wit...   True  \n",
       "1224  Put<s>add the rice and cook for 15 minutes lon...   True  \n",
       "1225  Check<s>add the rice and cook for 15 minutes l...   True  \n",
       "1226  Put<s>add the cheese , stir gently and turn of...   True  \n",
       "1227  Check<s>add the cheese , stir gently and turn ...   True  \n",
       "\n",
       "[1228 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = df.query(\"triplet_n<6\").explode(\"triplet_seq\")\n",
    "df_prep.index.name=\"sentence_index\"\n",
    "df_prep[\"command\"]  =  df_prep[\"triplet_seq\"].apply(lambda x: command2idx[x[0]])\n",
    "df_prep[\"arg\"]      =  df_prep[\"triplet_seq\"].apply(lambda x: arg2idx[x[1]])\n",
    "df_prep[\"resource\"] =  df_prep[\"triplet_seq\"].apply(lambda x: res2idx[x[2]])\n",
    "df_prep=df_prep[[\"input_seq\", \"command\", \"arg\", \"resource\"]].reset_index()\n",
    "df_prep[\"conditioned_seq\"] = df_prep[\"command\"].map(commands) + \" <s> \" + df_prep[\"input_seq\"]\n",
    "df_prep[\"train\"]=df_prep[\"sentence_index\"].isin(train_idx)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "median-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_prep[\"input_seq\"].str.split().str.len().plot.hist(density=True, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-eugene",
   "metadata": {},
   "source": [
    "# Command Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlike-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=20\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "corporate-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleInstructionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, text, train, target, max_length, **filters):\n",
    "        if filters:\n",
    "            for col,val in filters.items():\n",
    "                df=df[df[col]==val]\n",
    "        self.encodings = tokenizer(list(df[df[\"train\"]==train][text]), truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = list(df[df[\"train\"]==train][target])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# convert our tokenized data into a torch Dataset\n",
    "command_train_dataset = SingleInstructionDataset(df_prep, \"input_seq\", True,  \"command\", max_length)\n",
    "command_valid_dataset = SingleInstructionDataset(df_prep, \"input_seq\", False, \"command\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extreme-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "command_names = list(command2idx.keys())\n",
    "command_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(command_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "metropolitan-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1920' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/1920 04:04, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.700200</td>\n",
       "      <td>1.523156</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>869.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.363200</td>\n",
       "      <td>1.823683</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>955.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.286600</td>\n",
       "      <td>1.802947</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>952.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.182500</td>\n",
       "      <td>1.964798</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>959.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.103600</td>\n",
       "      <td>2.010527</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>967.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.062400</td>\n",
       "      <td>2.037496</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>966.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.006600</td>\n",
       "      <td>2.223601</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>964.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.965300</td>\n",
       "      <td>2.243315</td>\n",
       "      <td>0.376190</td>\n",
       "      <td>0.218700</td>\n",
       "      <td>960.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>2.212500</td>\n",
       "      <td>0.376190</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>955.665000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1920, training_loss=1.1601832071940104, metrics={'train_runtime': 245.4711, 'train_samples_per_second': 7.822, 'total_flos': 456823858003200.0, 'epoch': 30.0, 'init_mem_cpu_alloc_delta': 8125505, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 23295, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3096866, 'train_mem_gpu_alloc_delta': 2007215616, 'train_mem_cpu_peaked_delta': 154965869, 'train_mem_gpu_peaked_delta': 0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "command_trainer = Trainer(\n",
    "    model=command_model,                 # the instantiated Transformers model to be trained\n",
    "    args=command_training_args,                  # training arguments, defined above\n",
    "    train_dataset=command_train_dataset,         # training dataset\n",
    "    eval_dataset=command_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "command_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "south-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_model.save_pretrained(\"command_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ranking-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def command_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = command_model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return command_names[probs.argmax()]\n",
    "command_prediction(\"brown meat in large skillet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "funny-portal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PUT'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_prediction(\"add the onion , celery and tomaotes .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sorted-harassment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOVE_CONTENTS'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_prediction(\"stir until well mixed .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "square-guard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PUT'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_prediction(\"add sugar, lemon and spice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "comparable-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 0, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<s>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-princess",
   "metadata": {},
   "source": [
    "# Models for arg and resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "historic-philosophy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-56de5c58bd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roberta-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "arg_names = list(arg2idx.keys())\n",
    "arg_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(arg_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "racial-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5fcb8261a964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresource_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres2idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresource_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roberta-base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "resource_names = list(res2idx.keys())\n",
    "resource_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(resource_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_train_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", True,  \"arg\", max_length)\n",
    "arg_valid_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", False, \"arg\", max_length)\n",
    "resource_train_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", True,  \"resource\", max_length)\n",
    "resource_valid_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", False, \"resource\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "resource_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_trainer = Trainer(\n",
    "    model=arg_model,                 # the instantiated Transformers model to be trained\n",
    "    args=arg_training_args,                  # training arguments, defined above\n",
    "    train_dataset=arg_train_dataset,         # training dataset\n",
    "    eval_dataset=arg_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "resource_trainer = Trainer(\n",
    "    model=resource_model,                 # the instantiated Transformers model to be trained\n",
    "    args=resource_training_args,                  # training arguments, defined above\n",
    "    train_dataset=resource_train_dataset,         # training dataset\n",
    "    eval_dataset=resource_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "necessary-india",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-561ec019e642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresource_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# memory metrics - must set up as early as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_peak_memory_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "resource_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "better-scholar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>command</th>\n",
       "      <th>arg</th>\n",
       "      <th>resource</th>\n",
       "      <th>conditioned_seq</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>Use&lt;s&gt;brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Put&lt;s&gt;brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>Move&lt;s&gt;remove from heat and drain the fat , if...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "      <td>Use&lt;s&gt;remove from heat and drain the fat , if ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>497</td>\n",
       "      <td>then cover with hot water , season with walt a...</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;then cover with hot water , season wit...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>Put&lt;s&gt;add the rice and cook for 15 minutes lon...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;add the rice and cook for 15 minutes l...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>Put&lt;s&gt;add the cheese , stir gently and turn of...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>Check&lt;s&gt;add the cheese , stir gently and turn ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_index                                          input_seq  \\\n",
       "0                  0                      brown meat in a big skillet .   \n",
       "1                  0                      brown meat in a big skillet .   \n",
       "2                  0                      brown meat in a big skillet .   \n",
       "3                  1      remove from heat and drain the fat , if any .   \n",
       "4                  1      remove from heat and drain the fat , if any .   \n",
       "...              ...                                                ...   \n",
       "1223             497  then cover with hot water , season with walt a...   \n",
       "1224             498      add the rice and cook for 15 minutes longer .   \n",
       "1225             498      add the rice and cook for 15 minutes longer .   \n",
       "1226             499  add the cheese , stir gently and turn off the ...   \n",
       "1227             499  add the cheese , stir gently and turn off the ...   \n",
       "\n",
       "      command  arg  resource  \\\n",
       "0           3  143        11   \n",
       "1           1   52        11   \n",
       "2           5  119        11   \n",
       "3           7   11        21   \n",
       "4           3  143        21   \n",
       "...       ...  ...       ...   \n",
       "1223        5  128        11   \n",
       "1224        1   51        11   \n",
       "1225        5  128        11   \n",
       "1226        1   67        11   \n",
       "1227        5  128        11   \n",
       "\n",
       "                                        conditioned_seq  train  \n",
       "0                   Use<s>brown meat in a big skillet .   True  \n",
       "1                   Put<s>brown meat in a big skillet .   True  \n",
       "2                 Check<s>brown meat in a big skillet .   True  \n",
       "3     Move<s>remove from heat and drain the fat , if...   True  \n",
       "4     Use<s>remove from heat and drain the fat , if ...   True  \n",
       "...                                                 ...    ...  \n",
       "1223  Check<s>then cover with hot water , season wit...   True  \n",
       "1224  Put<s>add the rice and cook for 15 minutes lon...   True  \n",
       "1225  Check<s>add the rice and cook for 15 minutes l...   True  \n",
       "1226  Put<s>add the cheese , stir gently and turn of...   True  \n",
       "1227  Check<s>add the cheese , stir gently and turn ...   True  \n",
       "\n",
       "[1228 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-backing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
