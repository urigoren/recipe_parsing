{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "resistant-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, collections, itertools,random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-heather",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "documented-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = {\n",
    "    0:\"nothing\",\n",
    "    1:\"put\",\n",
    "    2:\"remove\",\n",
    "    3:\"use\",\n",
    "    4:\"unuse\",\n",
    "    5:\"check\",\n",
    "    6:\"do\",\n",
    "    7:\"move\",\n",
    "}\n",
    "command2idx = {\n",
    "        \"NOOP\": 0,\n",
    "        \"PUT\": 1,\n",
    "        \"REMOVE\": 2,\n",
    "        \"USE\": 3,\n",
    "        \"STOP_USING\": 4,\n",
    "        \"CHEF_CHECK\": 5,\n",
    "        \"CHEF_DO\": 6,\n",
    "        \"MOVE_CONTENTS\": 7,\n",
    "    }\n",
    "with open(\"../data/ingredients.json\", 'r') as f:\n",
    "    ingredients = dict(json.load(f))\n",
    "with open(\"../data/resources.json\", 'r') as f:\n",
    "    resources = json.load(f)\n",
    "    resources = [(r[\"id\"], r[\"name\"]) for r in resources if 'children' not in r] + [(r[\"id\"], lst[\"name\"]+'/'+r[\"name\"]) for lst in resources if 'children' in lst for r in lst[\"children\"]]\n",
    "    resources = {k:v for k,v in resources if not k.startswith(\"VALID_\")}\n",
    "    res2idx = {k:i for i,k in enumerate(resources.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driven-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg2idx = res2idx\n",
    "k=len(arg2idx)+1\n",
    "with open(\"../data/arg2idx.json\", 'r') as f:\n",
    "    for w, i in json.load(f).items():\n",
    "        arg2idx[w.replace('-', '_')] = k\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2arg = {i:ingredients.get(v,v) for v,i in arg2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-collection",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "saved-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_seq</th>\n",
       "      <th>output_seq</th>\n",
       "      <th>triplet_n</th>\n",
       "      <th>triplet_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>reduce heat .</td>\n",
       "      <td>MOVE_CONTENTS COUNTER1 STOVE_LOW MOVE_CONTENTS...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER1, STOVE_LOW], [MOVE_C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>dot with margarine .</td>\n",
       "      <td>PUT IzrIHcuDJ STOVE_LOW PUT Is_lS1dmt STOVE_LOW</td>\n",
       "      <td>2</td>\n",
       "      <td>[[PUT, IzrIHcuDJ, STOVE_LOW], [PUT, Is_lS1dmt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>bake 5 minutes more .</td>\n",
       "      <td>MOVE_CONTENTS COUNTER1 OVEN_MED MOVE_CONTENTS ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER1, OVEN_MED], [MOVE_CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>add a dash or two of dry mustard and about 1 t...</td>\n",
       "      <td>PUT IzDRSSnRu COUNTER1 PUT IfztrkJfj COUNTER1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[PUT, IzDRSSnRu, COUNTER1], [PUT, IfztrkJfj, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>( soak skewers in water for 1/2 hour before us...</td>\n",
       "      <td>MOVE_CONTENTS REF_CHIL COUNTER1 MOVE_CONTENTS ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[[MOVE_CONTENTS, REF_CHIL, COUNTER1], [MOVE_CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>remove to a paper towel to drain , then crumbl...</td>\n",
       "      <td>MOVE_CONTENTS STOVE_MED COUNTER1 USE TPAPER CO...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[MOVE_CONTENTS, STOVE_MED, COUNTER1], [USE, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>season to taste with salt and pepper .</td>\n",
       "      <td>MOVE_CONTENTS COUNTER2 COUNTER1 STOP_USING TBO...</td>\n",
       "      <td>4</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER2, COUNTER1], [STOP_US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>cook , tightly covered , for 3 hours .</td>\n",
       "      <td>MOVE_CONTENTS COUNTER1 STOVE_LOW USE TPOT STOV...</td>\n",
       "      <td>4</td>\n",
       "      <td>[[MOVE_CONTENTS, COUNTER1, STOVE_LOW], [USE, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>add salt and pepper to taste .</td>\n",
       "      <td>STOP_USING TFOIL COUNTER1 PUT IzrIHcuDJ COUNTER1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[STOP_USING, TFOIL, COUNTER1], [PUT, IzrIHcuD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>bring water to boil .</td>\n",
       "      <td>USE TPAN STOVE_HI PUT IlGA3C7DK STOVE_HI CHEF_...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[USE, TPAN, STOVE_HI], [PUT, IlGA3C7DK, STOVE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_seq  \\\n",
       "116                                      reduce heat .   \n",
       "125                               dot with margarine .   \n",
       "220                              bake 5 minutes more .   \n",
       "288  add a dash or two of dry mustard and about 1 t...   \n",
       "233  ( soak skewers in water for 1/2 hour before us...   \n",
       "303  remove to a paper towel to drain , then crumbl...   \n",
       "327             season to taste with salt and pepper .   \n",
       "388             cook , tightly covered , for 3 hours .   \n",
       "203                     add salt and pepper to taste .   \n",
       "472                              bring water to boil .   \n",
       "\n",
       "                                            output_seq  triplet_n  \\\n",
       "116  MOVE_CONTENTS COUNTER1 STOVE_LOW MOVE_CONTENTS...          5   \n",
       "125    PUT IzrIHcuDJ STOVE_LOW PUT Is_lS1dmt STOVE_LOW          2   \n",
       "220  MOVE_CONTENTS COUNTER1 OVEN_MED MOVE_CONTENTS ...          5   \n",
       "288      PUT IzDRSSnRu COUNTER1 PUT IfztrkJfj COUNTER1          2   \n",
       "233  MOVE_CONTENTS REF_CHIL COUNTER1 MOVE_CONTENTS ...          4   \n",
       "303  MOVE_CONTENTS STOVE_MED COUNTER1 USE TPAPER CO...          3   \n",
       "327  MOVE_CONTENTS COUNTER2 COUNTER1 STOP_USING TBO...          4   \n",
       "388  MOVE_CONTENTS COUNTER1 STOVE_LOW USE TPOT STOV...          4   \n",
       "203   STOP_USING TFOIL COUNTER1 PUT IzrIHcuDJ COUNTER1          2   \n",
       "472  USE TPAN STOVE_HI PUT IlGA3C7DK STOVE_HI CHEF_...          3   \n",
       "\n",
       "                                           triplet_seq  \n",
       "116  [[MOVE_CONTENTS, COUNTER1, STOVE_LOW], [MOVE_C...  \n",
       "125  [[PUT, IzrIHcuDJ, STOVE_LOW], [PUT, Is_lS1dmt,...  \n",
       "220  [[MOVE_CONTENTS, COUNTER1, OVEN_MED], [MOVE_CO...  \n",
       "288  [[PUT, IzDRSSnRu, COUNTER1], [PUT, IfztrkJfj, ...  \n",
       "233  [[MOVE_CONTENTS, REF_CHIL, COUNTER1], [MOVE_CO...  \n",
       "303  [[MOVE_CONTENTS, STOVE_MED, COUNTER1], [USE, T...  \n",
       "327  [[MOVE_CONTENTS, COUNTER2, COUNTER1], [STOP_US...  \n",
       "388  [[MOVE_CONTENTS, COUNTER1, STOVE_LOW], [USE, T...  \n",
       "203  [[STOP_USING, TFOIL, COUNTER1], [PUT, IzrIHcuD...  \n",
       "472  [[USE, TPAN, STOVE_HI], [PUT, IlGA3C7DK, STOVE...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def triplet_split(s):\n",
    "    ret = []\n",
    "    s=s.split()\n",
    "    for i,t in enumerate(s):\n",
    "        if i%3==0:\n",
    "            ret.append([])\n",
    "        ret[-1].append(t)\n",
    "    return ret\n",
    "df = pd.read_csv(\"seq2seq_4335716.csv\")\n",
    "df[\"triplet_n\"] = df[\"output_seq\"].str.split().str.len()//3\n",
    "df[\"triplet_seq\"] = df[\"output_seq\"].apply(triplet_split)\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overhead-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"triplet_n\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acute-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_idx = list(df.index)\n",
    "random.shuffle(sentence_idx)\n",
    "train_idx = sentence_idx[:int(0.8*len(sentence_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "reserved-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>triplet_seq</th>\n",
       "      <th>command</th>\n",
       "      <th>arg</th>\n",
       "      <th>resource</th>\n",
       "      <th>conditioned_seq</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[USE, TSKILLET, STOVE_MED]</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>use &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[PUT, INJApA96N, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[CHEF_CHECK, LBROWN, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>move &lt;s&gt; remove from heat and drain the fat , ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>[USE, TSKILLET, FAUCET_OFF]</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "      <td>use &lt;s&gt; remove from heat and drain the fat , i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>497</td>\n",
       "      <td>then cover with hot water , season with walt a...</td>\n",
       "      <td>[CHEF_CHECK, LTIME, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; then cover with hot water , season w...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>[PUT, IN2e0UIJI, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the rice and cook for 15 minutes l...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>[CHEF_CHECK, LTIME, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; add the rice and cook for 15 minutes...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>[PUT, I_qDx9v7e, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the cheese , stir gently and turn ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>[CHEF_CHECK, LTIME, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; add the cheese , stir gently and tur...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_index                                          input_seq  \\\n",
       "0                  0                      brown meat in a big skillet .   \n",
       "1                  0                      brown meat in a big skillet .   \n",
       "2                  0                      brown meat in a big skillet .   \n",
       "3                  1      remove from heat and drain the fat , if any .   \n",
       "4                  1      remove from heat and drain the fat , if any .   \n",
       "...              ...                                                ...   \n",
       "1223             497  then cover with hot water , season with walt a...   \n",
       "1224             498      add the rice and cook for 15 minutes longer .   \n",
       "1225             498      add the rice and cook for 15 minutes longer .   \n",
       "1226             499  add the cheese , stir gently and turn off the ...   \n",
       "1227             499  add the cheese , stir gently and turn off the ...   \n",
       "\n",
       "                                 triplet_seq  command  arg  resource  \\\n",
       "0                 [USE, TSKILLET, STOVE_MED]        3  143        11   \n",
       "1                [PUT, INJApA96N, STOVE_MED]        1   52        11   \n",
       "2            [CHEF_CHECK, LBROWN, STOVE_MED]        5  119        11   \n",
       "3     [MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]        7   11        21   \n",
       "4                [USE, TSKILLET, FAUCET_OFF]        3  143        21   \n",
       "...                                      ...      ...  ...       ...   \n",
       "1223          [CHEF_CHECK, LTIME, STOVE_MED]        5  128        11   \n",
       "1224             [PUT, IN2e0UIJI, STOVE_MED]        1   51        11   \n",
       "1225          [CHEF_CHECK, LTIME, STOVE_MED]        5  128        11   \n",
       "1226             [PUT, I_qDx9v7e, STOVE_MED]        1   67        11   \n",
       "1227          [CHEF_CHECK, LTIME, STOVE_MED]        5  128        11   \n",
       "\n",
       "                                        conditioned_seq  train  \n",
       "0                 use <s> brown meat in a big skillet .   True  \n",
       "1                 put <s> brown meat in a big skillet .   True  \n",
       "2               check <s> brown meat in a big skillet .   True  \n",
       "3     move <s> remove from heat and drain the fat , ...   True  \n",
       "4     use <s> remove from heat and drain the fat , i...   True  \n",
       "...                                                 ...    ...  \n",
       "1223  check <s> then cover with hot water , season w...  False  \n",
       "1224  put <s> add the rice and cook for 15 minutes l...   True  \n",
       "1225  check <s> add the rice and cook for 15 minutes...   True  \n",
       "1226  put <s> add the cheese , stir gently and turn ...   True  \n",
       "1227  check <s> add the cheese , stir gently and tur...   True  \n",
       "\n",
       "[1228 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = df.query(\"triplet_n<6\").explode(\"triplet_seq\")\n",
    "df_prep.index.name=\"sentence_index\"\n",
    "df_prep[\"command\"]  =  df_prep[\"triplet_seq\"].apply(lambda x: command2idx[x[0]])\n",
    "df_prep[\"arg\"]      =  df_prep[\"triplet_seq\"].apply(lambda x: arg2idx[x[1]])\n",
    "df_prep[\"resource\"] =  df_prep[\"triplet_seq\"].apply(lambda x: res2idx[x[2]])\n",
    "df_prep=df_prep[[\"input_seq\",\"triplet_seq\",  \"command\", \"arg\", \"resource\"]].reset_index()\n",
    "df_prep[\"conditioned_seq\"] = df_prep[\"command\"].map(commands) + \" <s> \" + df_prep[\"input_seq\"]\n",
    "df_prep[\"train\"]=df_prep[\"sentence_index\"].isin(train_idx)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compound-swaziland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_prep[\"input_seq\"].str.split().str.len().plot.hist(density=True, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlike-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=20\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prompt-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleInstructionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, text, train, target, max_length):\n",
    "        self.encodings = tokenizer(list(df[df[\"train\"]==train][text]), truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = list(df[df[\"train\"]==train][target])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-employee",
   "metadata": {},
   "source": [
    "# Command Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "virtual-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "command_train_dataset = SingleInstructionDataset(df_prep, \"input_seq\", True,  \"command\", max_length)\n",
    "command_valid_dataset = SingleInstructionDataset(df_prep, \"input_seq\", False, \"command\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "motivated-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "command_names = list(command2idx.keys())\n",
    "command_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(command_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "metropolitan-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='230' max='1830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 230/1830 00:29 < 03:25, 7.79 it/s, Epoch 3.75/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.704700</td>\n",
       "      <td>1.705677</td>\n",
       "      <td>0.300380</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>920.041000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-42aeac59383a>\", line 21, in <module>\n",
      "    command_trainer.train()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py\", line 1095, in train\n",
      "    self.optimizer.step()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/optimization.py\", line 347, in step\n",
      "    denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-42aeac59383a>\", line 21, in <module>\n",
      "    command_trainer.train()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py\", line 1095, in train\n",
      "    self.optimizer.step()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/optimization.py\", line 347, in step\n",
      "    denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3347, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-42aeac59383a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mcommand_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3346\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3347\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3348\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2056\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2057\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[1;32m   3154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3156\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3366\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2057\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1143\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "command_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "command_trainer = Trainer(\n",
    "    model=command_model,                 # the instantiated Transformers model to be trained\n",
    "    args=command_training_args,                  # training arguments, defined above\n",
    "    train_dataset=command_train_dataset,         # training dataset\n",
    "    eval_dataset=command_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "command_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_model.save_pretrained(\"command_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = command_model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return command_names[probs.argmax()]\n",
    "command_prediction(\"brown meat in large skillet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_prediction(\"add the onion , celery and tomaotes .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_prediction(\"stir until well mixed .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_prediction(\"add sugar, lemon and spice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"<s>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-merit",
   "metadata": {},
   "source": [
    "# Models for arg and resource\n",
    "## Arg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assigned-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_names = list(arg2idx.keys())\n",
    "arg_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(arg_names)).to(\"cuda\")\n",
    "arg_train_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", True,  \"arg\", max_length)\n",
    "arg_valid_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", False, \"arg\", max_length)\n",
    "arg_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    report_to=\"none\"\n",
    ")\n",
    "arg_trainer = Trainer(\n",
    "    model=arg_model,                 # the instantiated Transformers model to be trained\n",
    "    args=arg_training_args,                  # training arguments, defined above\n",
    "    train_dataset=arg_train_dataset,         # training dataset\n",
    "    eval_dataset=arg_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "arg_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_model.save_pretrained(\"arg_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-miller",
   "metadata": {},
   "source": [
    "## Resource Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "champion-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "resource_names = list(res2idx.keys())\n",
    "resource_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(resource_names)).to(\"cuda\")\n",
    "resource_train_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", True,  \"resource\", max_length)\n",
    "resource_valid_dataset = SingleInstructionDataset(df_prep, \"conditioned_seq\", False, \"resource\", max_length)\n",
    "resource_training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=30,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "resource_trainer = Trainer(\n",
    "    model=resource_model,                 # the instantiated Transformers model to be trained\n",
    "    args=resource_training_args,                  # training arguments, defined above\n",
    "    train_dataset=resource_train_dataset,         # training dataset\n",
    "    eval_dataset=resource_valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "german-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3', 4: 'LABEL_4', 5: 'LABEL_5', 6: 'LABEL_6', 7: 'LABEL_7', 8: 'LABEL_8', 9: 'LABEL_9', 10: 'LABEL_10', 11: 'LABEL_11', 12: 'LABEL_12', 13: 'LABEL_13', 14: 'LABEL_14', 15: 'LABEL_15', 16: 'LABEL_16', 17: 'LABEL_17', 18: 'LABEL_18', 19: 'LABEL_19', 20: 'LABEL_20', 21: 'LABEL_21', 22: 'LABEL_22', 23: 'LABEL_23', 24: 'LABEL_24', 25: 'LABEL_25', 26: 'LABEL_26', 27: 'LABEL_27', 28: 'LABEL_28', 29: 'LABEL_29', 30: 'LABEL_30', 31: 'LABEL_31', 32: 'LABEL_32', 33: 'LABEL_33', 34: 'LABEL_34', 35: 'LABEL_35', 36: 'LABEL_36', 37: 'LABEL_37', 38: 'LABEL_38', 39: 'LABEL_39', 40: 'LABEL_40', 41: 'LABEL_41', 42: 'LABEL_42', 43: 'LABEL_43', 44: 'LABEL_44', 45: 'LABEL_45', 46: 'LABEL_46', 47: 'LABEL_47', 48: 'LABEL_48', 49: 'LABEL_49', 50: 'LABEL_50', 51: 'LABEL_51', 52: 'LABEL_52', 53: 'LABEL_53', 54: 'LABEL_54', 55: 'LABEL_55', 56: 'LABEL_56', 57: 'LABEL_57', 58: 'LABEL_58', 59: 'LABEL_59', 60: 'LABEL_60', 61: 'LABEL_61', 62: 'LABEL_62', 63: 'LABEL_63', 64: 'LABEL_64', 65: 'LABEL_65', 66: 'LABEL_66', 67: 'LABEL_67', 68: 'LABEL_68', 69: 'LABEL_69', 70: 'LABEL_70', 71: 'LABEL_71', 72: 'LABEL_72', 73: 'LABEL_73', 74: 'LABEL_74', 75: 'LABEL_75', 76: 'LABEL_76', 77: 'LABEL_77', 78: 'LABEL_78', 79: 'LABEL_79', 80: 'LABEL_80', 81: 'LABEL_81', 82: 'LABEL_82', 83: 'LABEL_83', 84: 'LABEL_84', 85: 'LABEL_85', 86: 'LABEL_86', 87: 'LABEL_87', 88: 'LABEL_88', 89: 'LABEL_89', 90: 'LABEL_90', 91: 'LABEL_91', 92: 'LABEL_92', 93: 'LABEL_93', 94: 'LABEL_94', 95: 'LABEL_95', 96: 'LABEL_96', 97: 'LABEL_97', 98: 'LABEL_98', 99: 'LABEL_99', 100: 'LABEL_100', 101: 'LABEL_101', 102: 'LABEL_102', 103: 'LABEL_103', 104: 'LABEL_104', 105: 'LABEL_105', 106: 'LABEL_106', 107: 'LABEL_107', 108: 'LABEL_108', 109: 'LABEL_109', 110: 'LABEL_110', 111: 'LABEL_111', 112: 'LABEL_112', 113: 'LABEL_113', 114: 'LABEL_114', 115: 'LABEL_115', 116: 'LABEL_116', 117: 'LABEL_117', 118: 'LABEL_118', 119: 'LABEL_119', 120: 'LABEL_120', 121: 'LABEL_121', 122: 'LABEL_122', 123: 'LABEL_123', 124: 'LABEL_124', 125: 'LABEL_125', 126: 'LABEL_126', 127: 'LABEL_127', 128: 'LABEL_128', 129: 'LABEL_129', 130: 'LABEL_130', 131: 'LABEL_131', 132: 'LABEL_132', 133: 'LABEL_133', 134: 'LABEL_134', 135: 'LABEL_135', 136: 'LABEL_136', 137: 'LABEL_137', 138: 'LABEL_138', 139: 'LABEL_139', 140: 'LABEL_140', 141: 'LABEL_141', 142: 'LABEL_142', 143: 'LABEL_143'}\" for key \"id2label\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3, 'LABEL_4': 4, 'LABEL_5': 5, 'LABEL_6': 6, 'LABEL_7': 7, 'LABEL_8': 8, 'LABEL_9': 9, 'LABEL_10': 10, 'LABEL_11': 11, 'LABEL_12': 12, 'LABEL_13': 13, 'LABEL_14': 14, 'LABEL_15': 15, 'LABEL_16': 16, 'LABEL_17': 17, 'LABEL_18': 18, 'LABEL_19': 19, 'LABEL_20': 20, 'LABEL_21': 21, 'LABEL_22': 22, 'LABEL_23': 23, 'LABEL_24': 24, 'LABEL_25': 25, 'LABEL_26': 26, 'LABEL_27': 27, 'LABEL_28': 28, 'LABEL_29': 29, 'LABEL_30': 30, 'LABEL_31': 31, 'LABEL_32': 32, 'LABEL_33': 33, 'LABEL_34': 34, 'LABEL_35': 35, 'LABEL_36': 36, 'LABEL_37': 37, 'LABEL_38': 38, 'LABEL_39': 39, 'LABEL_40': 40, 'LABEL_41': 41, 'LABEL_42': 42, 'LABEL_43': 43, 'LABEL_44': 44, 'LABEL_45': 45, 'LABEL_46': 46, 'LABEL_47': 47, 'LABEL_48': 48, 'LABEL_49': 49, 'LABEL_50': 50, 'LABEL_51': 51, 'LABEL_52': 52, 'LABEL_53': 53, 'LABEL_54': 54, 'LABEL_55': 55, 'LABEL_56': 56, 'LABEL_57': 57, 'LABEL_58': 58, 'LABEL_59': 59, 'LABEL_60': 60, 'LABEL_61': 61, 'LABEL_62': 62, 'LABEL_63': 63, 'LABEL_64': 64, 'LABEL_65': 65, 'LABEL_66': 66, 'LABEL_67': 67, 'LABEL_68': 68, 'LABEL_69': 69, 'LABEL_70': 70, 'LABEL_71': 71, 'LABEL_72': 72, 'LABEL_73': 73, 'LABEL_74': 74, 'LABEL_75': 75, 'LABEL_76': 76, 'LABEL_77': 77, 'LABEL_78': 78, 'LABEL_79': 79, 'LABEL_80': 80, 'LABEL_81': 81, 'LABEL_82': 82, 'LABEL_83': 83, 'LABEL_84': 84, 'LABEL_85': 85, 'LABEL_86': 86, 'LABEL_87': 87, 'LABEL_88': 88, 'LABEL_89': 89, 'LABEL_90': 90, 'LABEL_91': 91, 'LABEL_92': 92, 'LABEL_93': 93, 'LABEL_94': 94, 'LABEL_95': 95, 'LABEL_96': 96, 'LABEL_97': 97, 'LABEL_98': 98, 'LABEL_99': 99, 'LABEL_100': 100, 'LABEL_101': 101, 'LABEL_102': 102, 'LABEL_103': 103, 'LABEL_104': 104, 'LABEL_105': 105, 'LABEL_106': 106, 'LABEL_107': 107, 'LABEL_108': 108, 'LABEL_109': 109, 'LABEL_110': 110, 'LABEL_111': 111, 'LABEL_112': 112, 'LABEL_113': 113, 'LABEL_114': 114, 'LABEL_115': 115, 'LABEL_116': 116, 'LABEL_117': 117, 'LABEL_118': 118, 'LABEL_119': 119, 'LABEL_120': 120, 'LABEL_121': 121, 'LABEL_122': 122, 'LABEL_123': 123, 'LABEL_124': 124, 'LABEL_125': 125, 'LABEL_126': 126, 'LABEL_127': 127, 'LABEL_128': 128, 'LABEL_129': 129, 'LABEL_130': 130, 'LABEL_131': 131, 'LABEL_132': 132, 'LABEL_133': 133, 'LABEL_134': 134, 'LABEL_135': 135, 'LABEL_136': 136, 'LABEL_137': 137, 'LABEL_138': 138, 'LABEL_139': 139, 'LABEL_140': 140, 'LABEL_141': 141, 'LABEL_142': 142, 'LABEL_143': 143}\" for key \"label2id\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 04:17, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.393200</td>\n",
       "      <td>2.114262</td>\n",
       "      <td>0.416974</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>819.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.557200</td>\n",
       "      <td>2.386361</td>\n",
       "      <td>0.450185</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>832.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.760100</td>\n",
       "      <td>2.726616</td>\n",
       "      <td>0.453875</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>888.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.389100</td>\n",
       "      <td>3.279024</td>\n",
       "      <td>0.435424</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>867.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>3.734532</td>\n",
       "      <td>0.453875</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>866.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>4.082107</td>\n",
       "      <td>0.476015</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>874.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>4.199569</td>\n",
       "      <td>0.464945</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>820.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>4.303107</td>\n",
       "      <td>0.490775</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>824.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>4.337808</td>\n",
       "      <td>0.498155</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>859.728000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.7286871165699429, metrics={'train_runtime': 258.4746, 'train_samples_per_second': 6.964, 'total_flos': 429810639033600.0, 'epoch': 30.0, 'init_mem_cpu_alloc_delta': 8127856, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 23615, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3116877, 'train_mem_gpu_alloc_delta': 2008889856, 'train_mem_cpu_peaked_delta': 154914210, 'train_mem_gpu_peaked_delta': 0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "known-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_model.save_pretrained(\"resource_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-japanese",
   "metadata": {},
   "source": [
    "# Bag of words model for ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "simplified-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_prep.query(\"train\")[\"input_seq\"]\n",
    "X_test = df_prep.query(\"not train\")[\"input_seq\"]\n",
    "y_train = df_prep.query(\"train\")[\"arg\"]\n",
    "y_test = df_prep.query(\"not train\")[\"arg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "coordinated-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_model = Pipeline([\n",
    "    (\"vec\", CountVectorizer(min_df=1, max_df=0.7, binary=True)),\n",
    "    (\"model\", BernoulliNB()),\n",
    "])\n",
    "arg_model.fit(X_train, y_train)\n",
    "y_pred = arg_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-requirement",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "directed-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_names = list(res2idx.keys())\n",
    "resource_model = RobertaForSequenceClassification.from_pretrained(\"resource_model\", num_labels=len(resource_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "changing-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_names = list(command2idx.keys())\n",
    "command_model = RobertaForSequenceClassification.from_pretrained(\"command_model\", num_labels=len(command_names)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "talented-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    # COMMAND MODEL\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = command_model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    cmd_idx = probs.argmax()\n",
    "    command = command_names[cmd_idx]\n",
    "    #RESOURCE MODEL\n",
    "    text = commands[int(cmd_idx.to('cpu'))] + \" </s> \" + text\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = resource_model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    res_idx = probs.argmax()\n",
    "    res = resource_names[res_idx]\n",
    "    arg = idx2arg[arg_model.predict([text])[0]]\n",
    "\n",
    "    return (command, arg, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "coordinated-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('USE', 'Skillet', 'STOVE_MED')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"brown meat in large skillet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "referenced-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"pred\"] = df_prep[\"input_seq\"].apply(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "electronic-reggae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>triplet_seq</th>\n",
       "      <th>command</th>\n",
       "      <th>arg</th>\n",
       "      <th>resource</th>\n",
       "      <th>conditioned_seq</th>\n",
       "      <th>train</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_triplet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[USE, TSKILLET, STOVE_MED]</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>use &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "      <td>(PUT, For X minutes, STOVE_MED)</td>\n",
       "      <td>(PUT, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[PUT, INJApA96N, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "      <td>(PUT, For X minutes, STOVE_MED)</td>\n",
       "      <td>(PUT, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>brown meat in a big skillet .</td>\n",
       "      <td>[CHEF_CHECK, LBROWN, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; brown meat in a big skillet .</td>\n",
       "      <td>True</td>\n",
       "      <td>(PUT, For X minutes, STOVE_MED)</td>\n",
       "      <td>(PUT, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>[MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>move &lt;s&gt; remove from heat and drain the fat , ...</td>\n",
       "      <td>True</td>\n",
       "      <td>(STOP_USING, For X minutes, STOVE_MED)</td>\n",
       "      <td>(STOP_USING, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>remove from heat and drain the fat , if any .</td>\n",
       "      <td>[USE, TSKILLET, FAUCET_OFF]</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "      <td>use &lt;s&gt; remove from heat and drain the fat , i...</td>\n",
       "      <td>True</td>\n",
       "      <td>(STOP_USING, For X minutes, STOVE_MED)</td>\n",
       "      <td>(STOP_USING, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>497</td>\n",
       "      <td>then cover with hot water , season with walt a...</td>\n",
       "      <td>[CHEF_CHECK, LTIME, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; then cover with hot water , season w...</td>\n",
       "      <td>False</td>\n",
       "      <td>(PUT, For X minutes, STOVE_MED)</td>\n",
       "      <td>(PUT, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>[PUT, IN2e0UIJI, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the rice and cook for 15 minutes l...</td>\n",
       "      <td>True</td>\n",
       "      <td>(PUT, For X minutes, STOVE_MED)</td>\n",
       "      <td>(PUT, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>498</td>\n",
       "      <td>add the rice and cook for 15 minutes longer .</td>\n",
       "      <td>[CHEF_CHECK, LTIME, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; add the rice and cook for 15 minutes...</td>\n",
       "      <td>True</td>\n",
       "      <td>(PUT, For X minutes, STOVE_MED)</td>\n",
       "      <td>(PUT, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>[PUT, I_qDx9v7e, STOVE_MED]</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>put &lt;s&gt; add the cheese , stir gently and turn ...</td>\n",
       "      <td>True</td>\n",
       "      <td>(CHEF_CHECK, For X minutes, STOVE_MED)</td>\n",
       "      <td>(CHEF_CHECK, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>499</td>\n",
       "      <td>add the cheese , stir gently and turn off the ...</td>\n",
       "      <td>[CHEF_CHECK, LTIME, STOVE_MED]</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>11</td>\n",
       "      <td>check &lt;s&gt; add the cheese , stir gently and tur...</td>\n",
       "      <td>True</td>\n",
       "      <td>(CHEF_CHECK, For X minutes, STOVE_MED)</td>\n",
       "      <td>(CHEF_CHECK, LTIME, STOVE_MED)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_index                                          input_seq  \\\n",
       "0                  0                      brown meat in a big skillet .   \n",
       "1                  0                      brown meat in a big skillet .   \n",
       "2                  0                      brown meat in a big skillet .   \n",
       "3                  1      remove from heat and drain the fat , if any .   \n",
       "4                  1      remove from heat and drain the fat , if any .   \n",
       "...              ...                                                ...   \n",
       "1223             497  then cover with hot water , season with walt a...   \n",
       "1224             498      add the rice and cook for 15 minutes longer .   \n",
       "1225             498      add the rice and cook for 15 minutes longer .   \n",
       "1226             499  add the cheese , stir gently and turn off the ...   \n",
       "1227             499  add the cheese , stir gently and turn off the ...   \n",
       "\n",
       "                                 triplet_seq  command  arg  resource  \\\n",
       "0                 [USE, TSKILLET, STOVE_MED]        3  143        11   \n",
       "1                [PUT, INJApA96N, STOVE_MED]        1   52        11   \n",
       "2            [CHEF_CHECK, LBROWN, STOVE_MED]        5  119        11   \n",
       "3     [MOVE_CONTENTS, STOVE_MED, FAUCET_OFF]        7   11        21   \n",
       "4                [USE, TSKILLET, FAUCET_OFF]        3  143        21   \n",
       "...                                      ...      ...  ...       ...   \n",
       "1223          [CHEF_CHECK, LTIME, STOVE_MED]        5  128        11   \n",
       "1224             [PUT, IN2e0UIJI, STOVE_MED]        1   51        11   \n",
       "1225          [CHEF_CHECK, LTIME, STOVE_MED]        5  128        11   \n",
       "1226             [PUT, I_qDx9v7e, STOVE_MED]        1   67        11   \n",
       "1227          [CHEF_CHECK, LTIME, STOVE_MED]        5  128        11   \n",
       "\n",
       "                                        conditioned_seq  train  \\\n",
       "0                 use <s> brown meat in a big skillet .   True   \n",
       "1                 put <s> brown meat in a big skillet .   True   \n",
       "2               check <s> brown meat in a big skillet .   True   \n",
       "3     move <s> remove from heat and drain the fat , ...   True   \n",
       "4     use <s> remove from heat and drain the fat , i...   True   \n",
       "...                                                 ...    ...   \n",
       "1223  check <s> then cover with hot water , season w...  False   \n",
       "1224  put <s> add the rice and cook for 15 minutes l...   True   \n",
       "1225  check <s> add the rice and cook for 15 minutes...   True   \n",
       "1226  put <s> add the cheese , stir gently and turn ...   True   \n",
       "1227  check <s> add the cheese , stir gently and tur...   True   \n",
       "\n",
       "                                        pred                    pred_triplet  \n",
       "0            (PUT, For X minutes, STOVE_MED)         (PUT, LTIME, STOVE_MED)  \n",
       "1            (PUT, For X minutes, STOVE_MED)         (PUT, LTIME, STOVE_MED)  \n",
       "2            (PUT, For X minutes, STOVE_MED)         (PUT, LTIME, STOVE_MED)  \n",
       "3     (STOP_USING, For X minutes, STOVE_MED)  (STOP_USING, LTIME, STOVE_MED)  \n",
       "4     (STOP_USING, For X minutes, STOVE_MED)  (STOP_USING, LTIME, STOVE_MED)  \n",
       "...                                      ...                             ...  \n",
       "1223         (PUT, For X minutes, STOVE_MED)         (PUT, LTIME, STOVE_MED)  \n",
       "1224         (PUT, For X minutes, STOVE_MED)         (PUT, LTIME, STOVE_MED)  \n",
       "1225         (PUT, For X minutes, STOVE_MED)         (PUT, LTIME, STOVE_MED)  \n",
       "1226  (CHEF_CHECK, For X minutes, STOVE_MED)  (CHEF_CHECK, LTIME, STOVE_MED)  \n",
       "1227  (CHEF_CHECK, For X minutes, STOVE_MED)  (CHEF_CHECK, LTIME, STOVE_MED)  \n",
       "\n",
       "[1228 rows x 10 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-backup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
